# 11. analyze - í”¼ì²˜ ìŠ¤í† ì–´ ë¶„ì„

## ê°œìš”
Feature Storeì˜ Offline Store(S3) ìŠ¤í† ë¦¬ì§€ ì‚¬ìš©ëŸ‰ê³¼ ë¹„ìš©ì„ ë¶„ì„í•©ë‹ˆë‹¤. íŒŒì¼ ìœ í˜•, ì›”ë³„ ì¦ê°€ ì¶”ì´, ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤ë³„ ë¶„ì„, ë¹„ìš© ì¶”ì • ë“± í¬ê´„ì ì¸ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.

âš ï¸ **ì£¼ì˜**: ì´ ëª…ë ¹ì–´ëŠ” Offline Store(S3)ë§Œ ë¶„ì„í•©ë‹ˆë‹¤. Online Store(DynamoDB)ëŠ” ë¶„ì„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

## ê¸°ë³¸ ì‚¬ìš©ë²•
```bash
fs analyze FEATURE_GROUP_NAME [OPTIONS]
```

ë˜ëŠ” S3 ìœ„ì¹˜ ì§ì ‘ ì§€ì •:
```bash
fs analyze --bucket BUCKET_NAME --prefix PREFIX [OPTIONS]
```

## í•„ìˆ˜ ì¸ì (ë‘˜ ì¤‘ í•˜ë‚˜)
- `FEATURE_GROUP_NAME`: ë¶„ì„í•  Feature Group ì´ë¦„
- `--bucket` + `--prefix`: S3 ìœ„ì¹˜ ì§ì ‘ ì§€ì •

## ì˜µì…˜
- `--export PATH`: ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°
- `--output-format [table|json]`: ì¶œë ¥ í˜•ì‹ (ê¸°ë³¸ê°’: table)

## ìƒì„¸ ì‚¬ìš© ì˜ˆì‹œ

### 1. Feature Group ë¶„ì„
```bash
fs analyze customer-profile
```

**ì¶œë ¥ ì˜ˆì‹œ:**
```
============================================================
Feature Store ì˜¤í”„ë¼ì¸ ìŠ¤í† ì–´ ë¶„ì„: s3://my-bucket/feature-store/
í”¼ì²˜ ê·¸ë£¹: customer-profile
âš ï¸  ì£¼ì˜: ì˜¤í”„ë¼ì¸ ìŠ¤í† ì–´(S3)ë§Œ ë¶„ì„ë©ë‹ˆë‹¤
============================================================

ğŸ“Š ì „ì²´ í†µê³„
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ì´ íŒŒì¼ ìˆ˜: 1,234
ì´ ìš©ëŸ‰:
  - Bytes: 12,345,678,901
  - MB: 11,773.46
  - GB: 11.50
  - TB: 0.01

ğŸ“ íŒŒì¼ ìœ í˜•ë³„ ë¶„ì„
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ìœ í˜•              ê°œìˆ˜        í¬ê¸°(MB)           ë¹„ìœ¨
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
parquet         1,200      11,500.20         97.7%
json                30         250.15          2.1%
csv                  4          23.11          0.2%
```

### 2. S3 ìœ„ì¹˜ ì§ì ‘ ë¶„ì„
```bash
fs analyze --bucket my-feature-bucket --prefix customer-data/
```

### 3. ê²°ê³¼ë¥¼ CSVë¡œ ë‚´ë³´ë‚´ê¸°
```bash
fs analyze customer-profile --export customer_analysis.csv
```

### 4. JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥
```bash
fs analyze customer-profile --output-format json
```

## ê³ ê¸‰ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤

### 1. ëª¨ë“  Feature Group ë¶„ì„ ë° ë¹„êµ
```bash
#!/bin/bash
analyze_all_feature_groups() {
  local output_dir=${1:-"/tmp/feature_analysis"}
  local threshold_gb=${2:-1.0}
  
  mkdir -p "$output_dir"
  
  echo "ğŸ“Š ì „ì²´ Feature Group ë¶„ì„ ì‹œì‘"
  echo "ì¶œë ¥ ë””ë ‰í† ë¦¬: $output_dir"
  echo "í¬ê¸° ì„ê³„ê°’: ${threshold_gb}GB ì´ìƒë§Œ ë¶„ì„"
  
  # ëª¨ë“  Feature Group ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
  feature_groups=($(fs list -o json | jq -r '.[].FeatureGroupName'))
  
  if [ ${#feature_groups[@]} -eq 0 ]; then
    echo "âŒ Feature Groupì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    return 1
  fi
  
  echo "ë¶„ì„ ëŒ€ìƒ: ${#feature_groups[@]}ê°œ Feature Group"
  
  # ë¶„ì„ ê²°ê³¼ ìš”ì•½ íŒŒì¼ ì´ˆê¸°í™”
  summary_file="$output_dir/summary_report.csv"
  echo "Feature_Group,Total_Files,Size_GB,Monthly_Cost_USD,Analysis_Date" > "$summary_file"
  
  analyzed_count=0
  skipped_count=0
  large_fgs=()
  
  for fg in "${feature_groups[@]}"; do
    echo ""
    echo "ğŸ” ë¶„ì„ ì¤‘: $fg"
    
    # ê°œë³„ Feature Group ë¶„ì„
    individual_report="$output_dir/${fg}_analysis.csv"
    
    if fs analyze "$fg" \
       --export "$individual_report" \
       --output-format json > "$output_dir/${fg}_analysis.json" 2>/dev/null; then
      
      # JSON ê²°ê³¼ì—ì„œ ì£¼ìš” ì •ë³´ ì¶”ì¶œ
      size_gb=$(jq -r '.total_size_gb // 0' "$output_dir/${fg}_analysis.json")
      total_files=$(jq -r '.total_files // 0' "$output_dir/${fg}_analysis.json")
      monthly_cost=$(jq -r '.estimated_monthly_cost // 0' "$output_dir/${fg}_analysis.json")
      analysis_date=$(jq -r '.analysis_timestamp // "N/A"' "$output_dir/${fg}_analysis.json")
      
      echo "  í¬ê¸°: ${size_gb}GB, íŒŒì¼: ${total_files}ê°œ, ì›” ë¹„ìš©: $${monthly_cost}"
      
      # ìš”ì•½ íŒŒì¼ì— ì¶”ê°€
      echo "$fg,$total_files,$size_gb,$monthly_cost,$analysis_date" >> "$summary_file"
      
      # ì„ê³„ê°’ ì´ìƒì¸ ê²½ìš° í‘œì‹œ
      if (( $(echo "$size_gb >= $threshold_gb" | bc -l) )); then
        large_fgs+=("$fg:${size_gb}GB")
        echo "  ğŸ“ˆ í° Feature Group ê°ì§€!"
      fi
      
      analyzed_count=$((analyzed_count + 1))
    else
      echo "  âš ï¸ ë¶„ì„ ì‹¤íŒ¨ (Offline Store ì—†ìŒ ë˜ëŠ” ê¶Œí•œ ë¶€ì¡±)"
      skipped_count=$((skipped_count + 1))
    fi
    
    # API í˜¸ì¶œ ì œí•œ ê³ ë ¤í•œ ë”œë ˆì´
    sleep 1
  done
  
  # ì „ì²´ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±
  echo ""
  echo "ğŸ“‹ ì „ì²´ ë¶„ì„ ì™„ë£Œ ìš”ì•½"
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
  echo "ì´ Feature Group ìˆ˜: ${#feature_groups[@]}"
  echo "ë¶„ì„ ì„±ê³µ: $analyzed_count"
  echo "ë¶„ì„ ì‹¤íŒ¨: $skipped_count"
  
  if [ ${#large_fgs[@]} -gt 0 ]; then
    echo ""
    echo "ğŸ˜ í° Feature Groups (${threshold_gb}GB ì´ìƒ):"
    for large_fg in "${large_fgs[@]}"; do
      IFS=':' read -r fg_name size <<< "$large_fg"
      echo "  - $fg_name: $size"
    done
  fi
  
  # Pythonì„ ì‚¬ìš©í•œ ì§‘ê³„ ë¶„ì„
  if [ -s "$summary_file" ]; then
    echo ""
    echo "ğŸ“Š ì§‘ê³„ í†µê³„ (Python ë¶„ì„):"
    
    python3 << EOF
import pandas as pd
import numpy as np

try:
    df = pd.read_csv('$summary_file')
    
    if len(df) > 0:
        total_size = df['Size_GB'].sum()
        total_cost = df['Monthly_Cost_USD'].sum()
        avg_size = df['Size_GB'].mean()
        median_size = df['Size_GB'].median()
        
        print(f"  ì´ ìŠ¤í† ë¦¬ì§€: {total_size:.2f}GB")
        print(f"  ì´ ì›”ê°„ ë¹„ìš©: ${total_cost:.2f}")
        print(f"  í‰ê·  í¬ê¸°: {avg_size:.2f}GB")
        print(f"  ì¤‘ê°„ê°’ í¬ê¸°: {median_size:.2f}GB")
        
        # ìƒìœ„ 5ê°œ Feature Group
        top5 = df.nlargest(5, 'Size_GB')
        print(f"\n  ğŸ’° ë¹„ìš© ìƒìœ„ 5ê°œ:")
        for _, row in top5.iterrows():
            print(f"    {row['Feature_Group']}: {row['Size_GB']:.2f}GB (${row['Monthly_Cost_USD']:.2f}/ì›”)")
            
    else:
        print("  ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
except Exception as e:
    print(f"  ì§‘ê³„ ë¶„ì„ ì˜¤ë¥˜: {e}")
EOF
  fi
  
  echo ""
  echo "ğŸ“ ë¶„ì„ ê²°ê³¼ íŒŒì¼ë“¤:"
  echo "  ìš”ì•½ ë¦¬í¬íŠ¸: $summary_file" 
  echo "  ê°œë³„ ë¶„ì„: $output_dir/*_analysis.csv"
  echo "  JSON ë°ì´í„°: $output_dir/*_analysis.json"
  
  echo ""
  echo "ğŸ‰ ì „ì²´ Feature Group ë¶„ì„ ì™„ë£Œ!"
}

# ì‚¬ìš© ì˜ˆì‹œ
analyze_all_feature_groups "/exports/feature_analysis" 5.0
```

### 2. ë¹„ìš© ìµœì í™” ê¶Œì¥ ì‚¬í•­ ìƒì„±
```bash
#!/bin/bash
cost_optimization_analysis() {
  local feature_group=$1
  local target_cost_reduction=${2:-20}  # 20% ë¹„ìš© ì ˆê° ëª©í‘œ
  
  echo "ğŸ’° ë¹„ìš© ìµœì í™” ë¶„ì„: $feature_group"
  echo "ëª©í‘œ ë¹„ìš© ì ˆê°: ${target_cost_reduction}%"
  
  # í˜„ì¬ ë¶„ì„ ì‹¤í–‰
  analysis_file="/tmp/${feature_group}_cost_analysis.json"
  
  if ! fs analyze "$feature_group" \
     --output-format json > "$analysis_file" 2>/dev/null; then
    echo "âŒ Feature Group ë¶„ì„ ì‹¤íŒ¨"
    return 1
  fi
  
  # Pythonì„ ì‚¬ìš©í•œ ìµœì í™” ë¶„ì„
  python3 << EOF
import json
from datetime import datetime, timedelta

# ë¶„ì„ ë°ì´í„° ë¡œë“œ
with open('$analysis_file', 'r') as f:
    data = json.load(f)

current_size_gb = data.get('total_size_gb', 0)
current_monthly_cost = data.get('estimated_monthly_cost', 0)
total_files = data.get('total_files', 0)
file_types = data.get('file_types', {})
monthly_stats = data.get('monthly_stats', [])

print(f"ğŸ“Š í˜„ì¬ ìƒí™© ë¶„ì„")
print(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
print(f"í˜„ì¬ í¬ê¸°: {current_size_gb:.2f}GB")
print(f"í˜„ì¬ ì›”ê°„ ë¹„ìš©: ${current_monthly_cost:.2f}")
print(f"ì´ íŒŒì¼ ìˆ˜: {total_files:,}")

target_savings = current_monthly_cost * $target_cost_reduction / 100
print(f"ëª©í‘œ ì ˆì•½ ê¸ˆì•¡: ${target_savings:.2f}/ì›” (${target_savings * 12:.2f}/ë…„)")

print(f"\nğŸ”§ ìµœì í™” ê¶Œì¥ì‚¬í•­")
print(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

recommendations = []
potential_savings = 0

# 1. ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤ ìµœì í™”
print(f"1. ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤ ìµœì í™”:")
if current_size_gb > 1:  # 1GB ì´ìƒì¸ ê²½ìš°
    # Standard IAë¡œ ì´ì „ ì‹œ ì ˆì•½ì•¡
    standard_ia_savings = current_size_gb * (0.023 - 0.0125)  # Standard vs IA
    print(f"   â†’ Standard IAë¡œ ì´ì „: ${standard_ia_savings:.2f}/ì›” ì ˆì•½")
    recommendations.append(("Storage Class IA", standard_ia_savings))
    
    # Glacierë¡œ ì´ì „ ì‹œ ì ˆì•½ì•¡ (ìì£¼ ì ‘ê·¼í•˜ì§€ ì•ŠëŠ” ê²½ìš°)
    if len(monthly_stats) > 6:  # 6ê°œì›” ì´ìƒ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°
        glacier_savings = current_size_gb * (0.023 - 0.004)  # Standard vs Glacier
        print(f"   â†’ Glacierë¡œ ì´ì „ (ì˜¤ë˜ëœ ë°ì´í„°): ${glacier_savings:.2f}/ì›” ì ˆì•½")
        recommendations.append(("Storage Class Glacier", glacier_savings * 0.5))  # 50%ë§Œ ì´ì „ ê°€ì •

# 2. ë°ì´í„° ì••ì¶• ë¶„ì„
print(f"\n2. ë°ì´í„° ì••ì¶•:")
parquet_size = file_types.get('parquet', {}).get('size', 0)
json_size = file_types.get('json', {}).get('size', 0)

if json_size > parquet_size * 0.1:  # JSONì´ ì „ì²´ì˜ 10% ì´ìƒì¸ ê²½ìš°
    json_gb = json_size / (1024**3)
    compression_savings = json_gb * 0.023 * 0.3  # 30% ì••ì¶•ë¥  ê°€ì •
    print(f"   â†’ JSONì„ Parquetìœ¼ë¡œ ë³€í™˜: ${compression_savings:.2f}/ì›” ì ˆì•½")
    recommendations.append(("Data Compression", compression_savings))

# 3. ë°ì´í„° ìƒëª…ì£¼ê¸° ê´€ë¦¬
print(f"\n3. ë°ì´í„° ìƒëª…ì£¼ê¸° ê´€ë¦¬:")
if len(monthly_stats) > 12:  # 1ë…„ ì´ìƒ ë°ì´í„°
    old_data_gb = sum([stat['size_gb'] for stat in monthly_stats[:-12]])  # 1ë…„ ì´ì „ ë°ì´í„°
    lifecycle_savings = old_data_gb * 0.023 * 0.8  # 80% ë¹„ìš© ì ˆê° (Glacier/Archive)
    print(f"   â†’ 1ë…„ ì´ìƒ ë°ì´í„° ì•„ì¹´ì´ë¸Œ: ${lifecycle_savings:.2f}/ì›” ì ˆì•½")
    recommendations.append(("Data Lifecycle", lifecycle_savings))

# 4. ë°ì´í„° ì¤‘ë³µ ì œê±°
print(f"\n4. ë°ì´í„° ìµœì í™”:")
if total_files > 10000:  # íŒŒì¼ì´ ë§ì€ ê²½ìš°
    dedup_savings = current_monthly_cost * 0.1  # 10% ì¤‘ë³µ ì œê±° ê°€ì •
    print(f"   â†’ ì¤‘ë³µ ë°ì´í„° ì œê±°: ${dedup_savings:.2f}/ì›” ì ˆì•½")
    recommendations.append(("Data Deduplication", dedup_savings))

# ê¶Œì¥ì‚¬í•­ ìš°ì„ ìˆœìœ„ ì •ë¦¬
recommendations.sort(key=lambda x: x[1], reverse=True)
total_potential_savings = sum([r[1] for r in recommendations])

print(f"\nğŸ“ˆ ìµœì í™” ìš”ì•½")
print(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
print(f"í˜„ì¬ ì›”ê°„ ë¹„ìš©: ${current_monthly_cost:.2f}")
print(f"ì ì¬ì  ì ˆì•½ì•¡: ${total_potential_savings:.2f}/ì›”")
print(f"ì ˆì•½ë¥ : {(total_potential_savings/current_monthly_cost)*100 if current_monthly_cost > 0 else 0:.1f}%")

if total_potential_savings >= target_savings:
    print(f"âœ… ëª©í‘œ ì ˆì•½ ê¸ˆì•¡ ë‹¬ì„± ê°€ëŠ¥!")
else:
    print(f"âš ï¸  ëª©í‘œì— ${target_savings - total_potential_savings:.2f} ë¶€ì¡±")

print(f"\nğŸ¯ ìš°ì„ ìˆœìœ„ë³„ ê¶Œì¥ì‚¬í•­:")
for i, (method, savings) in enumerate(recommendations[:5], 1):
    print(f"{i}. {method}: ${savings:.2f}/ì›”")
EOF
  
  echo ""
  echo "ğŸ“‹ ì‹¤í–‰ ê°€ëŠ¥í•œ ìµœì í™” ë‹¨ê³„:"
  echo "1. AWS S3 Intelligent Tiering í™œì„±í™”"
  echo "2. ì˜¤ë˜ëœ ë°ì´í„°ì— ëŒ€í•œ Lifecycle ì •ì±… ì„¤ì •" 
  echo "3. ë°ì´í„° í˜•ì‹ ìµœì í™” (JSON â†’ Parquet)"
  echo "4. ì •ê¸°ì ì¸ ë°ì´í„° ì •ë¦¬ ë° ì¤‘ë³µ ì œê±°"
  
  # ì •ë¦¬
  rm -f "$analysis_file"
}

cost_optimization_analysis "large-feature-group" 30
```

### 3. ë°ì´í„° ì¦ê°€ ì¶”ì„¸ ì˜ˆì¸¡
```bash
#!/bin/bash
growth_trend_analysis() {
  local feature_group=$1
  local prediction_months=${2:-6}
  
  echo "ğŸ“ˆ ë°ì´í„° ì¦ê°€ ì¶”ì„¸ ë¶„ì„: $feature_group"
  echo "ì˜ˆì¸¡ ê¸°ê°„: ${prediction_months}ê°œì›”"
  
  # ë¶„ì„ ì‹¤í–‰
  analysis_file="/tmp/${feature_group}_growth.json"
  
  if ! fs analyze "$feature_group" \
     --output-format json > "$analysis_file" 2>/dev/null; then
    echo "âŒ Feature Group ë¶„ì„ ì‹¤íŒ¨"
    return 1
  fi
  
  # Pythonì„ ì‚¬ìš©í•œ ì¶”ì„¸ ë¶„ì„
  python3 << EOF
import json
import numpy as np
import matplotlib
matplotlib.use('Agg')  # GUI ì—†ëŠ” í™˜ê²½ì—ì„œ ì‚¬ìš©
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
import pandas as pd

# ë¶„ì„ ë°ì´í„° ë¡œë“œ
with open('$analysis_file', 'r') as f:
    data = json.load(f)

monthly_stats = data.get('monthly_stats', [])
if len(monthly_stats) < 3:
    print("âŒ ì¶”ì„¸ ë¶„ì„ì— í•„ìš”í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤ (ìµœì†Œ 3ê°œì›” í•„ìš”)")
    exit(1)

# ë°ì´í„° ì¤€ë¹„
df = pd.DataFrame(monthly_stats)
df['month_num'] = range(len(df))
df['size_gb'] = df['size_gb'].astype(float)

print(f"ğŸ“Š ê¸°ì¡´ ë°ì´í„° ë¶„ì„ ({len(monthly_stats)}ê°œì›”)")
print(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

# ê¸°ë³¸ í†µê³„
total_growth = df['size_gb'].iloc[-1] - df['size_gb'].iloc[0] if len(df) > 1 else 0
avg_monthly_growth = total_growth / (len(df) - 1) if len(df) > 1 else 0
growth_rate = (df['size_gb'].iloc[-1] / df['size_gb'].iloc[0] - 1) * 100 if df['size_gb'].iloc[0] > 0 else 0

print(f"ì²« ë‹¬ í¬ê¸°: {df['size_gb'].iloc[0]:.2f}GB")
print(f"ìµœê·¼ ë‹¬ í¬ê¸°: {df['size_gb'].iloc[-1]:.2f}GB")
print(f"ì´ ì¦ê°€ëŸ‰: {total_growth:.2f}GB")
print(f"ì›”í‰ê·  ì¦ê°€: {avg_monthly_growth:.2f}GB")
print(f"ì¦ê°€ìœ¨: {growth_rate:.1f}%")

# ì¶”ì„¸ì„  ê³„ì‚° (ì„ í˜• íšŒê·€)
if len(df) > 2:
    from sklearn.linear_model import LinearRegression
    import warnings
    warnings.filterwarnings('ignore')
    
    X = df[['month_num']]
    y = df['size_gb']
    
    model = LinearRegression()
    model.fit(X, y)
    
    # ì˜ˆì¸¡
    future_months = range(len(df), len(df) + $prediction_months)
    future_X = [[month] for month in future_months]
    predictions = model.predict(future_X)
    
    print(f"\nğŸ”® ${prediction_months}ê°œì›” ì˜ˆì¸¡ (ì„ í˜• ì¶”ì„¸)")
    print(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    
    current_size = df['size_gb'].iloc[-1]
    predicted_size = predictions[-1]
    predicted_growth = predicted_size - current_size
    
    for i, (month_offset, pred_size) in enumerate(zip(future_months, predictions), 1):
        print(f"{i}ê°œì›” í›„: {pred_size:.2f}GB")
    
    print(f"\nì˜ˆìƒ ì¦ê°€ëŸ‰: {predicted_growth:.2f}GB")
    print(f"ì˜ˆìƒ ì¦ê°€ìœ¨: {(predicted_growth/current_size)*100:.1f}%")
    
    # ë¹„ìš© ì˜ˆì¸¡
    current_cost = data.get('estimated_monthly_cost', 0)
    cost_per_gb = current_cost / current_size if current_size > 0 else 0.023
    predicted_cost = predicted_size * cost_per_gb
    cost_increase = predicted_cost - current_cost
    
    print(f"\nğŸ’° ë¹„ìš© ì˜ˆì¸¡")
    print(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    print(f"í˜„ì¬ ì›”ê°„ ë¹„ìš©: ${current_cost:.2f}")
    print(f"ì˜ˆìƒ ì›”ê°„ ë¹„ìš©: ${predicted_cost:.2f}")
    print(f"ë¹„ìš© ì¦ê°€: ${cost_increase:.2f}/ì›”")
    print(f"ì—°ê°„ ì¶”ê°€ ë¹„ìš©: ${cost_increase * 12:.2f}")
    
    # ê²½ê³  ë° ê¶Œì¥ì‚¬í•­
    print(f"\nâš ï¸  ê²½ê³  ë° ê¶Œì¥ì‚¬í•­")
    print(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    
    if growth_rate > 50:  # 50% ì´ìƒ ì¦ê°€
        print(f"ğŸš¨ ë†’ì€ ì¦ê°€ìœ¨ ({growth_rate:.1f}%) ê°ì§€!")
        print(f"   â†’ ë°ì´í„° ì •ë¦¬ ì •ì±… ê²€í†  í•„ìš”")
        print(f"   â†’ ìŠ¤í† ë¦¬ì§€ ìµœì í™” ê³ ë ¤")
    
    if predicted_cost > current_cost * 2:
        print(f"ğŸ’¸ ë¹„ìš© ê¸‰ì¦ ì˜ˆìƒ ({(predicted_cost/current_cost)*100:.0f}%)")
        print(f"   â†’ ì˜ˆì‚° ê³„íš ì—…ë°ì´íŠ¸ í•„ìš”")
        print(f"   â†’ ë°ì´í„° ì•„ì¹´ì´ë¹™ ì •ì±… ìˆ˜ë¦½")
    
    if predicted_size > 100:  # 100GB ì´ˆê³¼ ì˜ˆìƒ
        print(f"ğŸ“¦ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì˜ˆìƒ ({predicted_size:.1f}GB)")
        print(f"   â†’ ë°ì´í„° íŒŒí‹°ì…”ë‹ ê³ ë ¤")
        print(f"   â†’ ì„±ëŠ¥ ìµœì í™” ê²€í† ")

else:
    print("âš ï¸ ì¶”ì„¸ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤")
EOF
  
  # ê·¸ë˜í”„ ìƒì„± (ì„ íƒì‚¬í•­)
  if command -v python3 >/dev/null && python3 -c "import matplotlib" 2>/dev/null; then
    echo ""
    echo "ğŸ“Š ì¶”ì„¸ ê·¸ë˜í”„ ìƒì„± ì¤‘..."
    
    python3 << EOF
import json
import matplotlib.pyplot as plt
import pandas as pd

with open('$analysis_file', 'r') as f:
    data = json.load(f)

monthly_stats = data.get('monthly_stats', [])
if len(monthly_stats) >= 3:
    df = pd.DataFrame(monthly_stats)
    
    plt.figure(figsize=(10, 6))
    plt.plot(range(len(df)), df['size_gb'], 'b-o', label='ì‹¤ì œ ë°ì´í„°')
    plt.title('$feature_group ë°ì´í„° ì¦ê°€ ì¶”ì„¸')
    plt.xlabel('ì›”')
    plt.ylabel('í¬ê¸° (GB)')
    plt.grid(True, alpha=0.3)
    plt.legend()
    plt.tight_layout()
    plt.savefig('/tmp/${feature_group}_growth_chart.png', dpi=150)
    print("ê·¸ë˜í”„ ì €ì¥: /tmp/${feature_group}_growth_chart.png")
EOF
  fi
  
  # ì •ë¦¬
  rm -f "$analysis_file"
}

growth_trend_analysis "analytics-features" 12
```

### 4. ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤ ìµœì í™” ë¶„ì„
```bash
#!/bin/bash
storage_class_optimization() {
  local feature_group=$1
  local access_pattern=${2:-"infrequent"}  # frequent, infrequent, archive
  
  echo "ğŸ’¾ ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤ ìµœì í™” ë¶„ì„: $feature_group"
  echo "ì ‘ê·¼ íŒ¨í„´: $access_pattern"
  
  # í˜„ì¬ ë¶„ì„
  current_analysis="/tmp/${feature_group}_current.json"
  
  if ! fs analyze "$feature_group" \
     --output-format json > "$current_analysis" 2>/dev/null; then
    echo "âŒ Feature Group ë¶„ì„ ì‹¤íŒ¨"
    return 1
  fi
  
  # ìµœì í™” ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„
  python3 << EOF
import json

# í˜„ì¬ ë°ì´í„° ë¡œë“œ
with open('$current_analysis', 'r') as f:
    current = json.load(f)

current_size_gb = current.get('total_size_gb', 0)
current_cost = current.get('estimated_monthly_cost', 0)

# ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤ë³„ ê°€ê²© (USD per GB per month)
storage_pricing = {
    'STANDARD': 0.023,
    'STANDARD_IA': 0.0125,
    'INTELLIGENT_TIERING': 0.0125,  # í‰ê· 
    'GLACIER': 0.004,
    'GLACIER_IR': 0.0036,
    'DEEP_ARCHIVE': 0.00099
}

# ì ‘ê·¼ íŒ¨í„´ë³„ ê¶Œì¥ í´ë˜ìŠ¤
access_recommendations = {
    'frequent': ['STANDARD', 'INTELLIGENT_TIERING'],
    'infrequent': ['STANDARD_IA', 'INTELLIGENT_TIERING', 'GLACIER_IR'],
    'archive': ['GLACIER', 'DEEP_ARCHIVE']
}

print(f"ğŸ“Š í˜„ì¬ ìƒí™©")
print(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
print(f"ë°ì´í„° í¬ê¸°: {current_size_gb:.2f}GB")
print(f"í˜„ì¬ ë¹„ìš©: ${current_cost:.2f}/ì›” (${current_cost*12:.2f}/ë…„)")
print(f"ì¶”ì • ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤: STANDARD")

print(f"\nğŸ’¡ ì ‘ê·¼ íŒ¨í„´ë³„ ìµœì í™” ì‹œë‚˜ë¦¬ì˜¤")
print(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

scenarios = []

for pattern in ['frequent', 'infrequent', 'archive']:
    print(f"\nğŸ“‹ {pattern.upper()} ì ‘ê·¼ íŒ¨í„´:")
    
    for storage_class in access_recommendations[pattern]:
        monthly_cost = current_size_gb * storage_pricing[storage_class]
        annual_cost = monthly_cost * 12
        savings = current_cost - monthly_cost
        annual_savings = savings * 12
        
        print(f"  {storage_class}:")
        print(f"    ì›”ê°„ ë¹„ìš©: ${monthly_cost:.2f}")
        print(f"    ì—°ê°„ ë¹„ìš©: ${annual_cost:.2f}")
        print(f"    ì›”ê°„ ì ˆì•½: ${savings:.2f}")
        print(f"    ì—°ê°„ ì ˆì•½: ${annual_savings:.2f}")
        
        scenarios.append({
            'pattern': pattern,
            'class': storage_class,
            'monthly_cost': monthly_cost,
            'monthly_savings': savings,
            'annual_savings': annual_savings
        })

# ìµœì  ì‹œë‚˜ë¦¬ì˜¤ ì°¾ê¸°
if '$access_pattern' in access_recommendations:
    best_scenarios = [s for s in scenarios if s['pattern'] == '$access_pattern']
    best_scenario = max(best_scenarios, key=lambda x: x['monthly_savings'])
    
    print(f"\nğŸ¯ ê¶Œì¥ ìµœì í™” (${access_pattern} íŒ¨í„´)")
    print(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    print(f"ìµœì  ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤: {best_scenario['class']}")
    print(f"ì˜ˆìƒ ì›”ê°„ ì ˆì•½: ${best_scenario['monthly_savings']:.2f}")
    print(f"ì˜ˆìƒ ì—°ê°„ ì ˆì•½: ${best_scenario['annual_savings']:.2f}")
    print(f"ì ˆì•½ë¥ : {(best_scenario['monthly_savings']/current_cost)*100:.1f}%")

print(f"\nğŸ“‹ êµ¬í˜„ ë‹¨ê³„")
print(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
print(f"1. S3 Lifecycle ì •ì±… ìƒì„±")
print(f"2. ê¸°ì¡´ ë°ì´í„° ì „í™˜ (ì ì§„ì )")
print(f"3. ìƒˆ ë°ì´í„° ìë™ ë¶„ë¥˜")
print(f"4. ëª¨ë‹ˆí„°ë§ ë° ìµœì í™”")

# S3 Lifecycle ì •ì±… ì˜ˆì‹œ ìƒì„±
bucket = current.get('bucket', 'your-bucket')
prefix = current.get('prefix', 'your-prefix')

lifecycle_policy = {
    "Rules": [
        {
            "ID": "FeatureStoreOptimization",
            "Status": "Enabled",
            "Filter": {"Prefix": prefix},
            "Transitions": []
        }
    ]
}

# ì ‘ê·¼ íŒ¨í„´ì— ë”°ë¥¸ ì „í™˜ ê·œì¹™ ì¶”ê°€
if '$access_pattern' == 'infrequent':
    lifecycle_policy["Rules"][0]["Transitions"] = [
        {"Days": 30, "StorageClass": "STANDARD_IA"},
        {"Days": 90, "StorageClass": "GLACIER"}
    ]
elif '$access_pattern' == 'archive':
    lifecycle_policy["Rules"][0]["Transitions"] = [
        {"Days": 1, "StorageClass": "GLACIER"},
        {"Days": 90, "StorageClass": "DEEP_ARCHIVE"}
    ]

print(f"\nğŸ“„ S3 Lifecycle ì •ì±… ì˜ˆì‹œ:")
print(json.dumps(lifecycle_policy, indent=2))

EOF
  
  echo ""
  echo "ğŸ”§ ì‹¤í–‰ ëª…ë ¹ì–´ ì˜ˆì‹œ:"
  echo "aws s3api put-bucket-lifecycle-configuration \\"
  echo "  --bucket YOUR_BUCKET \\"
  echo "  --lifecycle-configuration file://lifecycle-policy.json"
  
  # ì •ë¦¬
  rm -f "$current_analysis"
}

storage_class_optimization "historical-data" "archive"
```

### 5. ì •ê¸° ë¶„ì„ ë° ë¦¬í¬íŒ… ì‹œìŠ¤í…œ
```bash
#!/bin/bash
setup_periodic_analysis() {
  local feature_groups=("$@")
  local report_frequency=${1:-"weekly"}  # daily, weekly, monthly
  
  if [ ${#feature_groups[@]} -eq 0 ]; then
    echo "âŒ ë¶„ì„í•  Feature Groupì„ ì§€ì •í•´ì£¼ì„¸ìš”"
    return 1
  fi
  
  echo "ğŸ“… ì •ê¸° ë¶„ì„ ì‹œìŠ¤í…œ ì„¤ì •"
  echo "ì£¼ê¸°: $report_frequency"
  echo "ëŒ€ìƒ Feature Groups: ${feature_groups[*]}"
  
  # ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
  analysis_script="/usr/local/bin/feature_store_periodic_analysis.sh"
  
  cat << 'SCRIPT_EOF' > "$analysis_script"
#!/bin/bash
# ìë™ ìƒì„±ëœ Feature Store ì •ê¸° ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸

REPORT_DIR="/var/reports/feature_store"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
REPORT_DATE=$(date +"%Y-%m-%d")

mkdir -p "$REPORT_DIR"

# ë¡œê·¸ ì„¤ì •
exec 1> >(tee -a "$REPORT_DIR/analysis_log.txt")
exec 2>&1

echo "ğŸš€ Feature Store ì •ê¸° ë¶„ì„ ì‹œì‘: $(date)"
echo "ë¦¬í¬íŠ¸ ID: $TIMESTAMP"
echo ""

# ë¶„ì„í•  Feature Groups ëª©ë¡
FEATURE_GROUPS=("FEATURE_GROUPS_PLACEHOLDER")

# ì „ì²´ ìš”ì•½ ì´ˆê¸°í™”
SUMMARY_FILE="$REPORT_DIR/summary_$TIMESTAMP.csv"
echo "Feature_Group,Total_Files,Size_GB,Monthly_Cost_USD,Status,Analysis_Time" > "$SUMMARY_FILE"

total_size=0
total_cost=0
analysis_success=0
analysis_failed=0

# ê° Feature Group ë¶„ì„
for fg in "${FEATURE_GROUPS[@]}"; do
    echo "ğŸ” ë¶„ì„ ì¤‘: $fg"
    
    fg_report_dir="$REPORT_DIR/$fg"
    mkdir -p "$fg_report_dir"
    
    individual_csv="$fg_report_dir/${fg}_${TIMESTAMP}.csv"
    individual_json="$fg_report_dir/${fg}_${TIMESTAMP}.json"
    
    if fs analyze "$fg" \
       --export "$individual_csv" \
       --output-format json > "$individual_json" 2>/dev/null; then
        
        # JSONì—ì„œ ì •ë³´ ì¶”ì¶œ
        size_gb=$(jq -r '.total_size_gb // 0' "$individual_json")
        files=$(jq -r '.total_files // 0' "$individual_json")  
        cost=$(jq -r '.estimated_monthly_cost // 0' "$individual_json")
        
        total_size=$(echo "$total_size + $size_gb" | bc)
        total_cost=$(echo "$total_cost + $cost" | bc)
        analysis_success=$((analysis_success + 1))
        
        echo "  âœ… ì„±ê³µ: ${size_gb}GB, ${files}ê°œ íŒŒì¼, $${cost}/ì›”"
        echo "$fg,$files,$size_gb,$cost,SUCCESS,$(date -Iseconds)" >> "$SUMMARY_FILE"
        
    else
        echo "  âŒ ì‹¤íŒ¨: ë¶„ì„ ë¶ˆê°€"
        analysis_failed=$((analysis_failed + 1))
        echo "$fg,0,0,0,FAILED,$(date -Iseconds)" >> "$SUMMARY_FILE"
    fi
    
    echo ""
done

# ì „ì²´ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±
SUMMARY_REPORT="$REPORT_DIR/executive_summary_$TIMESTAMP.txt"

cat << EOF > "$SUMMARY_REPORT"
ğŸ“Š Feature Store ì •ê¸° ë¶„ì„ ë¦¬í¬íŠ¸
========================================
ìƒì„±ì¼: $REPORT_DATE
ë¦¬í¬íŠ¸ ID: $TIMESTAMP

ğŸ“ˆ ì „ì²´ í˜„í™©
--------
ë¶„ì„ ëŒ€ìƒ: ${#FEATURE_GROUPS[@]}ê°œ Feature Groups
ë¶„ì„ ì„±ê³µ: $analysis_success
ë¶„ì„ ì‹¤íŒ¨: $analysis_failed
ì´ ìŠ¤í† ë¦¬ì§€: ${total_size}GB
ì´ ì›”ê°„ ë¹„ìš©: \$${total_cost}
ì˜ˆìƒ ì—°ê°„ ë¹„ìš©: \$$(echo "$total_cost * 12" | bc)

ğŸ“ ìƒì„¸ ë¦¬í¬íŠ¸
--------
- ìš”ì•½ ë°ì´í„°: $SUMMARY_FILE
- ê°œë³„ ë¶„ì„: $REPORT_DIR/*/

EOF

# ì„ê³„ê°’ ê¸°ë°˜ ì•Œë¦¼
if (( $(echo "$total_cost > 100" | bc -l) )); then
    echo "âš ï¸  ë¹„ìš© ì•Œë¦¼: ì›”ê°„ ë¹„ìš©ì´ $100ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤ ($${total_cost})" >> "$SUMMARY_REPORT"
fi

if (( $(echo "$total_size > 500" | bc -l) )); then
    echo "ğŸ“¦ ìš©ëŸ‰ ì•Œë¦¼: ì´ ìŠ¤í† ë¦¬ì§€ê°€ 500GBë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤ (${total_size}GB)" >> "$SUMMARY_REPORT"
fi

echo "âœ… ì •ê¸° ë¶„ì„ ì™„ë£Œ: $(date)"
echo "ğŸ“‹ ìš”ì•½ ë¦¬í¬íŠ¸: $SUMMARY_REPORT"

# ì´ë©”ì¼ ë°œì†¡ (ì„ íƒì‚¬í•­)
if command -v mail >/dev/null && [ -n "$REPORT_EMAIL" ]; then
    mail -s "Feature Store ë¶„ì„ ë¦¬í¬íŠ¸ - $REPORT_DATE" "$REPORT_EMAIL" < "$SUMMARY_REPORT"
    echo "ğŸ“§ ë¦¬í¬íŠ¸ ì´ë©”ì¼ ë°œì†¡: $REPORT_EMAIL"
fi

SCRIPT_EOF
  
  # Feature Groups ëª©ë¡ì„ ìŠ¤í¬ë¦½íŠ¸ì— ì‚½ì…
  feature_groups_str=$(printf '"%s" ' "${feature_groups[@]}")
  sed -i "s/FEATURE_GROUPS_PLACEHOLDER/$feature_groups_str/g" "$analysis_script"
  
  chmod +x "$analysis_script"
  
  # Cron ì‘ì—… ì„¤ì •
  case $report_frequency in
    "daily")
      cron_expr="0 6 * * *"  # ë§¤ì¼ ì˜¤ì „ 6ì‹œ
      ;;
    "weekly")
      cron_expr="0 6 * * 1"  # ë§¤ì£¼ ì›”ìš”ì¼ ì˜¤ì „ 6ì‹œ
      ;;
    "monthly")
      cron_expr="0 6 1 * *"  # ë§¤ì›” 1ì¼ ì˜¤ì „ 6ì‹œ
      ;;
    *)
      cron_expr="0 6 * * 1"  # ê¸°ë³¸ê°’: ì£¼ê°„
      ;;
  esac
  
  echo ""
  echo "âœ… ì •ê¸° ë¶„ì„ ì‹œìŠ¤í…œ ì„¤ì • ì™„ë£Œ"
  echo "ğŸ“‹ ì„¤ì • ë‚´ìš©:"
  echo "  ìŠ¤í¬ë¦½íŠ¸: $analysis_script"
  echo "  ì‹¤í–‰ ì£¼ê¸°: $report_frequency ($cron_expr)"
  echo "  ë¦¬í¬íŠ¸ ì €ì¥: /var/reports/feature_store/"
  
  echo ""
  echo "ğŸ”§ Cron ì‘ì—… ì„¤ì¹˜:"
  echo "sudo mkdir -p /var/reports/feature_store"
  echo "sudo chown \$(whoami) /var/reports/feature_store"
  echo "(crontab -l 2>/dev/null; echo '$cron_expr $analysis_script') | crontab -"
  
  echo ""
  echo "ğŸ“§ ì´ë©”ì¼ ì•Œë¦¼ ì„¤ì • (ì„ íƒì‚¬í•­):"
  echo "export REPORT_EMAIL=your-email@company.com"
}

# ì‚¬ìš© ì˜ˆì‹œ
setup_periodic_analysis "weekly" "customer-features" "transaction-history" "user-analytics"
```

### 6. ë©€í‹° ë¦¬ì „ ë¶„ì„
```bash
#!/bin/bash
multi_region_analysis() {
  local regions=("$@")
  
  if [ ${#regions[@]} -eq 0 ]; then
    regions=("us-east-1" "us-west-2" "ap-northeast-2")
  fi
  
  echo "ğŸŒ ë©€í‹° ë¦¬ì „ Feature Store ë¶„ì„"
  echo "ëŒ€ìƒ ë¦¬ì „: ${regions[*]}"
  
  total_global_size=0
  total_global_cost=0
  region_summary=()
  
  for region in "${regions[@]}"; do
    echo ""
    echo "ğŸ“ ë¦¬ì „ ë¶„ì„: $region"
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    
    # í•´ë‹¹ ë¦¬ì „ì˜ Feature Groups ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    region_fgs=($(AWS_REGION="$region" fs list -o json | jq -r '.[].FeatureGroupName' 2>/dev/null || echo ""))
    
    if [ ${#region_fgs[@]} -eq 0 ]; then
      echo "  â„¹ï¸ í•´ë‹¹ ë¦¬ì „ì— Feature Groupì´ ì—†ìŠµë‹ˆë‹¤."
      region_summary+=("$region:0:0:0")
      continue
    fi
    
    echo "  Feature Groups: ${#region_fgs[@]}ê°œ"
    
    region_size=0
    region_cost=0
    region_analyzed=0
    
    for fg in "${region_fgs[@]}"; do
      echo "    ğŸ” $fg ë¶„ì„ ì¤‘..."
      
      # ì„ì‹œ íŒŒì¼
      temp_analysis="/tmp/${region}_${fg}_analysis.json"
      
      if AWS_REGION="$region" fs analyze "$fg" \
         --output-format json > "$temp_analysis" 2>/dev/null; then
        
        fg_size=$(jq -r '.total_size_gb // 0' "$temp_analysis")
        fg_cost=$(jq -r '.estimated_monthly_cost // 0' "$temp_analysis")
        
        region_size=$(echo "$region_size + $fg_size" | bc)
        region_cost=$(echo "$region_cost + $fg_cost" | bc)
        region_analyzed=$((region_analyzed + 1))
        
        echo "      âœ… ${fg_size}GB, $${fg_cost}/ì›”"
        
        rm -f "$temp_analysis"
      else
        echo "      âš ï¸ ë¶„ì„ ì‹¤íŒ¨"
      fi
    done
    
    total_global_size=$(echo "$total_global_size + $region_size" | bc)
    total_global_cost=$(echo "$total_global_cost + $region_cost" | bc)
    
    echo "  ğŸ“Š $region ìš”ì•½:"
    echo "    ì´ í¬ê¸°: ${region_size}GB"  
    echo "    ì›”ê°„ ë¹„ìš©: $${region_cost}"
    echo "    ë¶„ì„ ì„±ê³µ: $region_analyzed/${#region_fgs[@]}"
    
    region_summary+=("$region:${#region_fgs[@]}:$region_size:$region_cost")
  done
  
  # ê¸€ë¡œë²Œ ìš”ì•½
  echo ""
  echo "ğŸŒ ê¸€ë¡œë²Œ ìš”ì•½"
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
  echo "ì´ ë¦¬ì „ ìˆ˜: ${#regions[@]}"
  echo "ì´ ìŠ¤í† ë¦¬ì§€: ${total_global_size}GB"
  echo "ì´ ì›”ê°„ ë¹„ìš©: $${total_global_cost}"
  echo "ì˜ˆìƒ ì—°ê°„ ë¹„ìš©: $$(echo "$total_global_cost * 12" | bc)"
  
  # ë¦¬ì „ë³„ ë¹„êµ
  echo ""
  echo "ğŸ“‹ ë¦¬ì „ë³„ ë¹„êµ"
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
  printf "%-15s %10s %15s %15s\n" "ë¦¬ì „" "FG ìˆ˜" "í¬ê¸°(GB)" "ë¹„ìš©(/ì›”)"
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
  
  for summary in "${region_summary[@]}"; do
    IFS=':' read -r region fg_count size cost <<< "$summary"
    printf "%-15s %10s %15s %15s\n" "$region" "$fg_count" "$size" "\$${cost}"
  done
  
  # ìµœì í™” ê¶Œì¥ì‚¬í•­
  echo ""
  echo "ğŸ’¡ ê¸€ë¡œë²Œ ìµœì í™” ê¶Œì¥ì‚¬í•­"
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
  
  # ê°€ì¥ ë¹„ìš©ì´ ë†’ì€ ë¦¬ì „ ì°¾ê¸°
  max_cost=0
  max_region=""
  for summary in "${region_summary[@]}"; do
    IFS=':' read -r region fg_count size cost <<< "$summary"
    if (( $(echo "$cost > $max_cost" | bc -l) )); then
      max_cost=$cost
      max_region=$region
    fi
  done
  
  echo "1. ìµœëŒ€ ë¹„ìš© ë¦¬ì „: $max_region (\$${max_cost}/ì›”)"
  echo "   â†’ í•´ë‹¹ ë¦¬ì „ ìš°ì„  ìµœì í™” ê¶Œì¥"
  
  if (( $(echo "$total_global_cost > 500" | bc -l) )); then
    echo "2. ê³ ë¹„ìš© í™˜ê²½ ê°ì§€ (\$${total_global_cost}/ì›”)"
    echo "   â†’ ê¸€ë¡œë²Œ ë°ì´í„° ìƒëª…ì£¼ê¸° ì •ì±… ìˆ˜ë¦½"
  fi
  
  echo "3. ë¦¬ì „ ê°„ ë°ì´í„° ì¤‘ë³µ í™•ì¸"
  echo "   â†’ ë¶ˆí•„ìš”í•œ ë¦¬ì „ ê°„ ë³µì œ ì œê±°"
  
  echo "4. ë¦¬ì „ë³„ ì ‘ê·¼ íŒ¨í„´ ë¶„ì„"
  echo "   â†’ ì§€ì—­ íŠ¹ì„±ì— ë§ëŠ” ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤ ì ìš©"
}

# ì‚¬ìš© ì˜ˆì‹œ
multi_region_analysis "us-east-1" "us-west-2" "eu-west-1" "ap-northeast-2"
```

## ì„±ëŠ¥ ë° ì œí•œì‚¬í•­

### 1. ë¶„ì„ ì„±ëŠ¥ ìµœì í™”
```bash
#!/bin/bash
optimize_analysis_performance() {
  local feature_group=$1
  
  echo "âš¡ ë¶„ì„ ì„±ëŠ¥ ìµœì í™”: $feature_group"
  
  # ì‚¬ì „ ì²´í¬: ë°ì´í„° í¬ê¸° ì¶”ì •
  echo "ğŸ“ ë°ì´í„° í¬ê¸° ì‚¬ì „ ì¶”ì • ì¤‘..."
  
  # Feature Group ì •ë³´ë¡œë¶€í„° S3 ìœ„ì¹˜ í™•ì¸
  fg_info=$(fs list -o json | jq --arg fg "$feature_group" \
    '.[] | select(.FeatureGroupName == $fg)')
  
  if [ -z "$fg_info" ]; then
    echo "âŒ Feature Groupì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
    return 1
  fi
  
  # Offline Store ì¡´ì¬ ì—¬ë¶€ í™•ì¸
  has_offline=$(echo "$fg_info" | jq -r '.IngestMode | contains("Offline")')
  
  if [ "$has_offline" != "true" ]; then
    echo "â„¹ï¸ Offline Storeê°€ ì—†ì–´ì„œ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
    return 0
  fi
  
  # ë¶„ì„ ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
  echo "â±ï¸ ì„±ëŠ¥ ì¸¡ì • ì‹œì‘..."
  start_time=$(date +%s.%N)
  
  if fs analyze "$feature_group" > "/tmp/perf_test_output.txt" 2>&1; then
    end_time=$(date +%s.%N)
    duration=$(echo "$end_time - $start_time" | bc)
    
    # ê²°ê³¼ ë¶„ì„
    total_files=$(grep "ì´ íŒŒì¼ ìˆ˜:" "/tmp/perf_test_output.txt" | grep -o '[0-9,]*' | tr -d ',')
    total_gb=$(grep "GB:" "/tmp/perf_test_output.txt" | head -1 | grep -o '[0-9,.]*' | tr -d ',')
    
    echo "ğŸ“Š ì„±ëŠ¥ ê²°ê³¼:"
    echo "  ì²˜ë¦¬ ì‹œê°„: ${duration}ì´ˆ"
    echo "  ì²˜ë¦¬í•œ íŒŒì¼: ${total_files:-0}ê°œ"
    echo "  ë°ì´í„° í¬ê¸°: ${total_gb:-0}GB"
    
    if [ -n "$total_files" ] && [ "$total_files" -gt 0 ]; then
      files_per_sec=$(echo "scale=2; $total_files / $duration" | bc)
      echo "  ì²˜ë¦¬ ì†ë„: ${files_per_sec} íŒŒì¼/ì´ˆ"
    fi
    
    # ì„±ëŠ¥ ê¶Œì¥ì‚¬í•­
    echo ""
    echo "ğŸš€ ì„±ëŠ¥ ìµœì í™” ê¶Œì¥ì‚¬í•­:"
    
    if [ -n "$duration" ] && (( $(echo "$duration > 60" | bc -l) )); then
      echo "  - ë¶„ì„ ì‹œê°„ì´ ê¹ë‹ˆë‹¤ (${duration}ì´ˆ)"
      echo "  - ë” ì‘ì€ ë²”ìœ„ë¡œ ë¶„ì„ ê³ ë ¤"
      echo "  - S3 Transfer Acceleration í™œì„±í™” ê²€í† "
    fi
    
    if [ -n "$total_files" ] && [ "$total_files" -gt 100000 ]; then
      echo "  - íŒŒì¼ ìˆ˜ê°€ ë§ìŠµë‹ˆë‹¤ (${total_files}ê°œ)"
      echo "  - íŒŒì¼ í†µí•©ì„ í†µí•œ ìµœì í™” ê³ ë ¤"
    fi
    
  else
    echo "âŒ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨"
    cat "/tmp/perf_test_output.txt"
  fi
  
  # ì •ë¦¬
  rm -f "/tmp/perf_test_output.txt"
}
```

## ì˜¤ë¥˜ ì²˜ë¦¬ ë° ë¬¸ì œ í•´ê²°

### 1. ì¼ë°˜ì ì¸ ë¶„ì„ ì˜¤ë¥˜
```bash
# S3 ê¶Œí•œ ì˜¤ë¥˜
âŒ S3 ì•¡ì„¸ìŠ¤ ì˜¤ë¥˜: Access Denied
# í•´ê²°: S3 ë²„í‚·ì— ëŒ€í•œ ListBucket, GetObject ê¶Œí•œ í•„ìš”

# Feature Group ì—†ìŒ
âŒ í”¼ì²˜ ê·¸ë£¹ 'non-existent' ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ResourceNotFound
# í•´ê²°: Feature Group ì´ë¦„ í™•ì¸

# Offline Store ì—†ìŒ
âŒ ì§€ì •ëœ ìœ„ì¹˜ì—ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤
# í•´ê²°: Feature Groupì´ Offline Storeë¥¼ ê°€ì§€ê³  ìˆëŠ”ì§€ í™•ì¸

# í° ë°ì´í„°ì…‹ ë¶„ì„ ì‹œê°„ ì´ˆê³¼
âŒ ë¶„ì„ì´ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤
# í•´ê²°: ë” ì‘ì€ ë²”ìœ„ë¡œ ë¶„í•  ë¶„ì„ ë˜ëŠ” ìƒ˜í”Œë§ ì‚¬ìš©
```

### 2. ë¶„ì„ ë³µêµ¬ ë° ì¬ì‹œë„
```bash
#!/bin/bash
retry_failed_analysis() {
  local feature_group=$1
  local max_retries=${2:-3}
  
  echo "ğŸ”„ ë¶„ì„ ì¬ì‹œë„: $feature_group"
  
  for attempt in $(seq 1 $max_retries); do
    echo "ì‹œë„ $attempt/$max_retries..."
    
    if fs analyze "$feature_group" --output-format json > "/tmp/retry_$attempt.json" 2>/dev/null; then
      echo "âœ… $attemptë²ˆì§¸ ì‹œë„ ì„±ê³µ"
      cat "/tmp/retry_$attempt.json"
      rm -f "/tmp/retry_$attempt.json"
      return 0
    else
      echo "âŒ $attemptë²ˆì§¸ ì‹œë„ ì‹¤íŒ¨"
      if [ $attempt -lt $max_retries ]; then
        sleep_time=$((attempt * 10))
        echo "  ${sleep_time}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„..."
        sleep $sleep_time
      fi
    fi
  done
  
  echo "ğŸ’¥ ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨"
  return 1
}
```

## ëª¨ë²” ì‚¬ë¡€

1. **ì •ê¸°ì  ë¶„ì„**: ì›”ë³„ ë˜ëŠ” ì£¼ë³„ë¡œ ì •ê¸°ì ì¸ ë¶„ì„ ì‹¤í–‰
2. **ë¹„ìš© ëª¨ë‹ˆí„°ë§**: ì„ê³„ê°’ ê¸°ë°˜ ì•Œë¦¼ ì‹œìŠ¤í…œ êµ¬ì¶•  
3. **íŠ¸ë Œë“œ ë¶„ì„**: ë°ì´í„° ì¦ê°€ ì¶”ì„¸ ëª¨ë‹ˆí„°ë§
4. **ìµœì í™” ê²€í† **: ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ìŠ¤í† ë¦¬ì§€ ìµœì í™”
5. **ë‹¤ì¤‘ ë¦¬ì „ ê´€ë¦¬**: ê¸€ë¡œë²Œ í™˜ê²½ì—ì„œ ë¦¬ì „ë³„ ë¶„ì„
6. **ìë™í™”**: ìŠ¤í¬ë¦½íŠ¸ë¥¼ í†µí•œ ë¶„ì„ ìë™í™”

## ê´€ë ¨ ëª…ë ¹ì–´
- `fs export`: ìƒì„¸ ë°ì´í„° ë¶„ì„ì„ ìœ„í•œ ë°ì´í„° ë‚´ë³´ë‚´ê¸°
- `fs list`: Feature Group í˜„í™© íŒŒì•…
- `fs create`: ìƒˆ Feature Group ìƒì„± ì‹œ ìŠ¤í† ë¦¬ì§€ ê³„íš
- `fs delete`: ë¶ˆí•„ìš”í•œ Feature Group ì •ë¦¬