# 10. delete - 피처 그룹 완전 삭제

## 개요
Feature Group을 완전히 삭제합니다. Online Store, Offline Store, 관련 메타데이터를 모두 제거하며, 되돌릴 수 없는 영구적인 작업입니다.

⚠️ **위험**: 이 작업은 되돌릴 수 없습니다. 중요한 데이터는 반드시 백업하세요.

## 기본 사용법
```bash
fs delete FEATURE_GROUP_NAME [OPTIONS]
```

## 필수 인자
- `FEATURE_GROUP_NAME`: 삭제할 Feature Group 이름

## 옵션
- `--force/--no-force`: 확인 없이 강제 삭제 (기본값: False)
- `--delete-data/--keep-data`: 데이터 삭제 여부 (기본값: True)
- `--wait/--no-wait`: 삭제 완료까지 대기 여부 (기본값: True)
- `--dry-run`: 실제 삭제 없이 삭제 계획만 표시

## 상세 사용 예시

### 1. 기본 삭제 (확인 포함)
```bash
fs delete old-feature-group
```

**실행 과정:**
1. Feature Group 상태 검증
2. 종속성 확인
3. 삭제 계획 표시
4. 사용자 확인 ('yes' 입력 필요)
5. 삭제 실행 및 완료 대기

### 2. 강제 삭제 (확인 없음)
```bash
fs delete temp-feature-group --force
```

### 3. 데이터 보존 삭제
```bash
fs delete archive-feature-group --keep-data
```

### 4. 백그라운드 삭제
```bash
fs delete large-feature-group --no-wait
```

### 5. 삭제 계획 확인 (실제 삭제 안함)
```bash
fs delete test-feature-group --dry-run
```

**출력 예시:**
```
Feature Group: test-feature-group
  상태: Created
  Online Store: 활성화됨
  Offline Store: 활성화됨 (s3://my-bucket/feature-store/)

삭제 순서:
  1. ✓ Online Store 비활성화
  2. ✓ Online 데이터 삭제
  3. ✓ Offline 데이터 삭제 (S3 및 Athena)
  4. ✓ Feature Group 리소스 삭제
  5. ✓ 관련 메타데이터 정리

예상 소요 시간: 3-8분
복구 가능성: 불가능
```

## 고급 사용 시나리오

### 1. 안전한 삭제 워크플로우
```bash
#!/bin/bash
safe_delete_workflow() {
  local feature_group=$1
  local backup_location=${2:-"s3://backups/feature-groups/"}
  
  echo "🛡️ 안전한 삭제 워크플로우: $feature_group"
  
  # 1. 현재 상태 확인
  echo "📊 1단계: Feature Group 상태 확인"
  fg_info=$(fs list -o json | jq --arg fg "$feature_group" \
    '.[] | select(.FeatureGroupName == $fg)')
  
  if [ -z "$fg_info" ]; then
    echo "❌ Feature Group을 찾을 수 없습니다: $feature_group"
    return 1
  fi
  
  status=$(echo "$fg_info" | jq -r '.FeatureGroupStatus')
  echo "현재 상태: $status"
  
  if [ "$status" != "Created" ]; then
    echo "⚠️ Feature Group이 Created 상태가 아닙니다. 삭제를 진행할 수 없습니다."
    return 1
  fi
  
  # 2. 종속성 검사
  echo "🔍 2단계: 종속성 및 사용 현황 검사"
  
  # 최근 데이터 활동 확인
  echo "최근 데이터 활동 확인 중..."
  recent_data=$(fs export "$feature_group" "/tmp/recent_check.json" \
    --limit 5 --format json 2>/dev/null || echo "")
  
  if [ -n "$recent_data" ] && [ -s "/tmp/recent_check.json" ]; then
    latest_time=$(jq -r '.[0].event_time // "N/A"' "/tmp/recent_check.json" 2>/dev/null || echo "N/A")
    echo "최근 데이터: $latest_time"
  else
    echo "최근 데이터: 없음 또는 조회 불가"
  fi
  
  rm -f "/tmp/recent_check.json"
  
  # 3. 스키마 백업
  echo "📋 3단계: 스키마 백업"
  schema_backup="/tmp/${feature_group}_schema_backup.json"
  fs schema "$feature_group" -o json > "$schema_backup"
  
  if [ -s "$schema_backup" ]; then
    echo "✅ 스키마 백업: $schema_backup"
  else
    echo "⚠️ 스키마 백업 실패"
  fi
  
  # 4. 데이터 샘플 백업 (있는 경우)
  echo "📦 4단계: 데이터 샘플 백업"
  sample_backup="/tmp/${feature_group}_sample_backup.json"
  
  if fs export "$feature_group" "$sample_backup" \
     --limit 100 --format json 2>/dev/null; then
    echo "✅ 데이터 샘플 백업: $sample_backup"
  else
    echo "ℹ️ 데이터 샘플 백업 불가 (Offline Store 없음 또는 데이터 없음)"
  fi
  
  # 5. 전체 데이터 백업 옵션
  if [ -n "$backup_location" ]; then
    echo "☁️ 5단계: 전체 데이터 백업 (옵션)"
    read -p "전체 데이터를 $backup_location 에 백업하시겠습니까? (y/n): " backup_choice
    
    if [ "$backup_choice" = "y" ]; then
      full_backup="/tmp/${feature_group}_full_backup.json"
      
      if fs export "$feature_group" "$full_backup" \
         --format json --compress; then
        
        # S3에 업로드
        aws s3 cp "${full_backup}.gz" \
          "${backup_location}${feature_group}_backup_$(date +%Y%m%d_%H%M%S).json.gz"
        
        if [ $? -eq 0 ]; then
          echo "✅ 전체 데이터 백업 완료: $backup_location"
        else
          echo "⚠️ S3 백업 업로드 실패"
        fi
        
        rm -f "$full_backup" "${full_backup}.gz"
      else
        echo "⚠️ 전체 데이터 백업 실패"
      fi
    fi
  fi
  
  # 6. 삭제 계획 확인
  echo "🔍 6단계: 삭제 계획 확인"
  fs delete "$feature_group" --dry-run
  
  # 7. 최종 확인
  echo ""
  echo "📋 백업 파일 요약:"
  ls -la /tmp/${feature_group}_* 2>/dev/null || echo "  백업 파일 없음"
  
  echo ""
  echo "⚠️ 최종 확인:"
  echo "  - Feature Group: $feature_group"
  echo "  - 현재 상태: $status"
  echo "  - 백업 완료: $([ -f "$schema_backup" ] && echo "스키마" || echo "없음")"
  
  read -p "위 정보를 확인했으며 삭제를 진행하시겠습니까? (DELETE 입력): " final_confirmation
  
  if [ "$final_confirmation" = "DELETE" ]; then
    echo "🗑️ 7단계: 삭제 실행"
    fs delete "$feature_group" --force
    
    if [ $? -eq 0 ]; then
      echo "✅ 안전한 삭제 완료"
      echo "📁 백업 파일들:"
      ls -la /tmp/${feature_group}_* 2>/dev/null
    else
      echo "❌ 삭제 실패"
      return 1
    fi
  else
    echo "❌ 삭제가 취소되었습니다."
    return 1
  fi
}

# 사용 예시
safe_delete_workflow "deprecated-feature-group" "s3://my-backups/safe-delete/"
```

### 2. 배치 삭제 (여러 Feature Group)
```bash
#!/bin/bash
batch_delete_feature_groups() {
  local pattern=$1
  local force_mode=${2:-false}
  local backup_base=${3:-""}
  
  echo "🧹 배치 삭제 프로세스: 패턴 '$pattern'"
  
  # 매칭되는 Feature Group 찾기
  matching_fgs=($(fs list -o json | jq -r --arg pattern "$pattern" \
    '.[] | select(.FeatureGroupName | test($pattern)) | .FeatureGroupName'))
  
  if [ ${#matching_fgs[@]} -eq 0 ]; then
    echo "❌ 패턴에 매칭되는 Feature Group이 없습니다: $pattern"
    return 1
  fi
  
  echo "📋 삭제 대상 (${#matching_fgs[@]}개):"
  printf '  - %s\n' "${matching_fgs[@]}"
  
  # 상태 검증
  echo ""
  echo "📊 상태 검증:"
  invalid_fgs=()
  for fg in "${matching_fgs[@]}"; do
    status=$(fs list -o json | jq -r --arg fg "$fg" \
      '.[] | select(.FeatureGroupName == $fg) | .FeatureGroupStatus')
    
    if [ "$status" != "Created" ]; then
      invalid_fgs+=("$fg ($status)")
    fi
    
    echo "  $fg: $status"
  done
  
  if [ ${#invalid_fgs[@]} -gt 0 ]; then
    echo ""
    echo "⚠️ 다음 Feature Group들은 삭제할 수 없는 상태입니다:"
    printf '  - %s\n' "${invalid_fgs[@]}"
    
    read -p "유효한 Feature Group만 삭제를 진행하시겠습니까? (y/n): " proceed
    if [ "$proceed" != "y" ]; then
      echo "❌ 배치 삭제 취소"
      return 1
    fi
  fi
  
  # 백업 설정
  if [ -n "$backup_base" ]; then
    echo ""
    echo "📦 배치 백업 시작"
    backup_timestamp=$(date +%Y%m%d_%H%M%S)
    
    for fg in "${matching_fgs[@]}"; do
      status=$(fs list -o json | jq -r --arg fg "$fg" \
        '.[] | select(.FeatureGroupName == $fg) | .FeatureGroupStatus')
      
      if [ "$status" = "Created" ]; then
        echo "  백업 중: $fg"
        
        # 스키마 백업
        fs schema "$fg" -o json > "/tmp/${fg}_schema_${backup_timestamp}.json"
        
        # 데이터 백업 (가능한 경우)
        if fs export "$fg" "/tmp/${fg}_data_${backup_timestamp}.json" \
           --limit 1000 --format json 2>/dev/null; then
          
          # S3에 업로드
          aws s3 cp "/tmp/${fg}_schema_${backup_timestamp}.json" \
            "${backup_base}schemas/${fg}_schema_${backup_timestamp}.json" 2>/dev/null
          aws s3 cp "/tmp/${fg}_data_${backup_timestamp}.json" \
            "${backup_base}data/${fg}_data_${backup_timestamp}.json" 2>/dev/null
          
          rm -f "/tmp/${fg}_schema_${backup_timestamp}.json"
          rm -f "/tmp/${fg}_data_${backup_timestamp}.json"
          
          echo "    ✅ $fg 백업 완료"
        else
          echo "    ⚠️ $fg 데이터 백업 실패 (스키마만 백업)"
        fi
      fi
    done
  fi
  
  # 최종 확인
  if [ "$force_mode" != "true" ]; then
    echo ""
    echo "⚠️ 최종 경고:"
    echo "  ${#matching_fgs[@]}개의 Feature Group이 영구적으로 삭제됩니다."
    echo "  이 작업은 되돌릴 수 없습니다."
    
    read -p "정말로 모든 Feature Group을 삭제하시겠습니까? (CONFIRM 입력): " final_confirm
    
    if [ "$final_confirm" != "CONFIRM" ]; then
      echo "❌ 배치 삭제 취소"
      return 1
    fi
  fi
  
  # 삭제 실행
  echo ""
  echo "🗑️ 배치 삭제 실행"
  success_count=0
  failure_count=0
  failed_fgs=()
  
  for fg in "${matching_fgs[@]}"; do
    status=$(fs list -o json | jq -r --arg fg "$fg" \
      '.[] | select(.FeatureGroupName == $fg) | .FeatureGroupStatus')
    
    if [ "$status" = "Created" ]; then
      echo "  삭제 중: $fg"
      
      if fs delete "$fg" --force --no-wait; then
        echo "    ✅ $fg 삭제 요청 성공"
        success_count=$((success_count + 1))
      else
        echo "    ❌ $fg 삭제 요청 실패"
        failure_count=$((failure_count + 1))
        failed_fgs+=("$fg")
      fi
    else
      echo "  ⏭️ $fg 건너뛰기 ($status 상태)"
    fi
  done
  
  # 결과 요약
  echo ""
  echo "📊 배치 삭제 결과:"
  echo "  성공: $success_count"
  echo "  실패: $failure_count"
  echo "  전체: ${#matching_fgs[@]}"
  
  if [ ${#failed_fgs[@]} -gt 0 ]; then
    echo "  실패한 Feature Groups:"
    printf '    - %s\n' "${failed_fgs[@]}"
  fi
  
  if [ $success_count -gt 0 ]; then
    echo ""
    echo "⏳ 백그라운드에서 삭제가 진행됩니다."
    echo "진행 상황 확인: fs list | grep -E '$(echo "${matching_fgs[*]}" | sed 's/ /|/g')'"
  fi
}

# 사용 예시
batch_delete_feature_groups "^test-.*" false "s3://backups/batch-delete/"
batch_delete_feature_groups "^temp-" true  # 강제 모드
```

### 3. 조건부 삭제 (사용량 기반)
```bash
#!/bin/bash
usage_based_delete() {
  local max_age_days=${1:-30}
  local min_size_gb=${2:-0.1}
  local dry_run=${3:-true}
  
  echo "📊 사용량 기반 조건부 삭제"
  echo "조건: ${max_age_days}일 이상 된 것, ${min_size_gb}GB 이하"
  
  # 모든 Feature Group 분석
  candidates=()
  
  while IFS= read -r fg_name; do
    if [ -z "$fg_name" ]; then continue; fi
    
    echo "🔍 분석 중: $fg_name"
    
    # 생성일 확인
    fg_info=$(fs list -o json | jq --arg fg "$fg_name" \
      '.[] | select(.FeatureGroupName == $fg)')
    
    if [ -z "$fg_info" ]; then continue; fi
    
    creation_time=$(echo "$fg_info" | jq -r '.CreationTime')
    if [ "$creation_time" = "null" ]; then continue; fi
    
    # 나이 계산
    creation_date=$(date -d "$creation_time" +%s 2>/dev/null || continue)
    current_date=$(date +%s)
    age_days=$(( (current_date - creation_date) / 86400 ))
    
    echo "  생성일: $creation_time (${age_days}일 전)"
    
    # 나이 조건 확인
    if [ $age_days -lt $max_age_days ]; then
      echo "  ⏭️ 너무 최근 생성됨 (${age_days} < ${max_age_days})"
      continue
    fi
    
    # 크기 확인 (analyze 명령 사용)
    size_info=""
    if fs analyze "$fg_name" --output-format json > "/tmp/${fg_name}_analysis.json" 2>/dev/null; then
      size_bytes=$(jq -r '.total_size_bytes // 0' "/tmp/${fg_name}_analysis.json")
      size_gb=$(echo "scale=2; $size_bytes / (1024^3)" | bc 2>/dev/null || echo "0")
      
      echo "  크기: ${size_gb}GB"
      
      # 크기 조건 확인  
      if (( $(echo "$size_gb > $min_size_gb" | bc -l) )); then
        echo "  ⏭️ 크기가 너무 큼 (${size_gb}GB > ${min_size_gb}GB)"
        rm -f "/tmp/${fg_name}_analysis.json"
        continue
      fi
      
      size_info="(${size_gb}GB)"
    else
      echo "  ⚠️ 크기 정보 없음"
      size_info="(크기 불명)"
    fi
    
    rm -f "/tmp/${fg_name}_analysis.json"
    
    # 조건을 만족하는 경우
    echo "  ✅ 삭제 조건 만족"
    candidates+=("$fg_name:$age_days:$size_info")
    
  done < <(fs list -o json | jq -r '.[].FeatureGroupName')
  
  # 삭제 대상 요약
  if [ ${#candidates[@]} -eq 0 ]; then
    echo ""
    echo "ℹ️ 삭제 조건을 만족하는 Feature Group이 없습니다."
    return 0
  fi
  
  echo ""
  echo "📋 삭제 후보 (${#candidates[@]}개):"
  for candidate in "${candidates[@]}"; do
    IFS=':' read -r fg_name age_days size_info <<< "$candidate"
    echo "  - $fg_name (${age_days}일, ${size_info})"
  done
  
  if [ "$dry_run" = "true" ]; then
    echo ""
    echo "🔍 Dry-run 모드: 실제 삭제는 수행되지 않습니다."
    echo "실제 삭제하려면: usage_based_delete $max_age_days $min_size_gb false"
    return 0
  fi
  
  # 실제 삭제 확인
  echo ""
  read -p "위 ${#candidates[@]}개 Feature Group을 삭제하시겠습니까? (yes/no): " confirm
  
  if [ "$confirm" != "yes" ]; then
    echo "❌ 삭제 취소"
    return 0
  fi
  
  # 삭제 실행
  echo "🗑️ 조건부 삭제 실행"
  success_count=0
  
  for candidate in "${candidates[@]}"; do
    IFS=':' read -r fg_name age_days size_info <<< "$candidate"
    
    echo "  삭제 중: $fg_name"
    if fs delete "$fg_name" --force --no-wait; then
      echo "    ✅ 성공"
      success_count=$((success_count + 1))
    else
      echo "    ❌ 실패"
    fi
  done
  
  echo ""
  echo "📊 조건부 삭제 결과: $success_count/${#candidates[@]} 성공"
}

# 사용 예시
usage_based_delete 90 1.0 true   # 90일 이상, 1GB 이하, dry-run
usage_based_delete 30 0.5 false  # 30일 이상, 0.5GB 이하, 실제 삭제
```

### 4. 의존성 체크 삭제
```bash
#!/bin/bash
dependency_aware_delete() {
  local feature_group=$1
  local check_ml_models=${2:-true}
  local check_pipelines=${3:-true}
  
  echo "🔗 의존성 체크 삭제: $feature_group"
  
  dependencies_found=false
  dependency_list=()
  
  # 1. SageMaker 모델 의존성 확인
  if [ "$check_ml_models" = "true" ]; then
    echo "🤖 ML 모델 의존성 확인 중..."
    
    # SageMaker 모델들 확인
    models=$(aws sagemaker list-models --query 'Models[].ModelName' --output text 2>/dev/null || echo "")
    
    if [ -n "$models" ]; then
      for model in $models; do
        # 모델 설명에서 Feature Group 참조 확인 (실제로는 더 정교한 검사 필요)
        model_info=$(aws sagemaker describe-model --model-name "$model" 2>/dev/null || echo "")
        
        if echo "$model_info" | grep -q "$feature_group" 2>/dev/null; then
          echo "  ⚠️ 모델에서 참조됨: $model"
          dependency_list+=("ML Model: $model")
          dependencies_found=true
        fi
      done
    fi
  fi
  
  # 2. SageMaker 파이프라인 의존성 확인
  if [ "$check_pipelines" = "true" ]; then
    echo "🔄 파이프라인 의존성 확인 중..."
    
    # SageMaker 파이프라인들 확인
    pipelines=$(aws sagemaker list-pipelines --query 'PipelineSummaries[].PipelineName' --output text 2>/dev/null || echo "")
    
    if [ -n "$pipelines" ]; then
      for pipeline in $pipelines; do
        # 파이프라인 정의에서 Feature Group 참조 확인
        pipeline_def=$(aws sagemaker describe-pipeline --pipeline-name "$pipeline" --query 'PipelineDefinition' --output text 2>/dev/null || echo "")
        
        if echo "$pipeline_def" | grep -q "$feature_group" 2>/dev/null; then
          echo "  ⚠️ 파이프라인에서 참조됨: $pipeline"
          dependency_list+=("Pipeline: $pipeline")
          dependencies_found=true
        fi
      done
    fi
  fi
  
  # 3. CloudFormation 스택 확인
  echo "☁️ CloudFormation 스택 확인 중..."
  stacks=$(aws cloudformation list-stacks --stack-status-filter CREATE_COMPLETE UPDATE_COMPLETE \
    --query 'StackSummaries[].StackName' --output text 2>/dev/null || echo "")
  
  if [ -n "$stacks" ]; then
    for stack in $stacks; do
      # 스택 리소스에서 Feature Group 확인
      if aws cloudformation list-stack-resources --stack-name "$stack" \
         --query 'StackResourceSummaries[].LogicalResourceId' --output text 2>/dev/null | \
         grep -q "$feature_group" 2>/dev/null; then
        echo "  ⚠️ CloudFormation 스택에서 관리됨: $stack"
        dependency_list+=("CloudFormation: $stack")
        dependencies_found=true
      fi
    done
  fi
  
  # 4. Lambda 함수 확인
  echo "⚡ Lambda 함수 확인 중..."
  functions=$(aws lambda list-functions --query 'Functions[].FunctionName' --output text 2>/dev/null || echo "")
  
  if [ -n "$functions" ]; then
    for func in $functions; do
      # Lambda 함수 코드나 환경 변수에서 Feature Group 참조 확인
      func_config=$(aws lambda get-function-configuration --function-name "$func" 2>/dev/null || echo "")
      
      if echo "$func_config" | grep -q "$feature_group" 2>/dev/null; then
        echo "  ⚠️ Lambda 함수에서 참조됨: $func"
        dependency_list+=("Lambda: $func")
        dependencies_found=true
      fi
    done
  fi
  
  # 5. 최근 접근 로그 확인 (CloudTrail)
  echo "📊 최근 접근 로그 확인 중..."
  recent_access=""
  
  # CloudTrail에서 최근 7일간의 Feature Group 접근 확인
  end_time=$(date -u +"%Y-%m-%dT%H:%M:%S.000Z")
  start_time=$(date -u -d "7 days ago" +"%Y-%m-%dT%H:%M:%S.000Z")
  
  events=$(aws cloudtrail lookup-events \
    --lookup-attributes AttributeKey=ResourceName,AttributeValue="$feature_group" \
    --start-time "$start_time" \
    --end-time "$end_time" \
    --query 'Events[].EventTime' --output text 2>/dev/null || echo "")
  
  if [ -n "$events" ]; then
    event_count=$(echo "$events" | wc -w)
    recent_access="최근 7일간 $event_count 회 접근"
    echo "  📈 $recent_access"
    dependency_list+=("Recent Activity: $recent_access")
    dependencies_found=true
  else
    echo "  ✅ 최근 접근 기록 없음"
  fi
  
  # 결과 요약
  echo ""
  echo "📋 의존성 검사 결과:"
  
  if [ "$dependencies_found" = "true" ]; then
    echo "⚠️ 다음 의존성들이 발견되었습니다:"
    for dep in "${dependency_list[@]}"; do
      echo "  - $dep"
    done
    
    echo ""
    echo "🚨 경고: Feature Group을 삭제하면 위 리소스들이 영향을 받을 수 있습니다."
    
    # 강제 삭제 여부 확인
    read -p "의존성이 있음에도 불구하고 삭제를 진행하시겠습니까? (FORCE 입력): " force_confirm
    
    if [ "$force_confirm" = "FORCE" ]; then
      echo "⚠️ 의존성 무시하고 강제 삭제 진행"
      fs delete "$feature_group" --force
    else
      echo "❌ 의존성으로 인해 삭제 취소"
      echo ""
      echo "💡 권장 사항:"
      echo "  1. 의존성 리소스들을 먼저 수정/제거"
      echo "  2. 의존성이 해결된 후 다시 삭제 시도"
      return 1
    fi
  else
    echo "✅ 의존성이 발견되지 않았습니다."
    echo "안전하게 삭제를 진행할 수 있습니다."
    
    # 일반 삭제 진행
    fs delete "$feature_group"
  fi
}

# 사용 예시
dependency_aware_delete "production-features" true true
```

### 5. 단계적 삭제 (Large Feature Group)
```bash
#!/bin/bash
staged_delete() {
  local feature_group=$1
  local stage_interval_minutes=${2:-30}
  
  echo "🎭 단계적 삭제: $feature_group"
  echo "단계별 간격: ${stage_interval_minutes}분"
  
  # 1. Feature Group 정보 확인
  echo "📊 1단계: Feature Group 분석"
  fg_info=$(fs list -o json | jq --arg fg "$feature_group" \
    '.[] | select(.FeatureGroupName == $fg)')
  
  if [ -z "$fg_info" ]; then
    echo "❌ Feature Group을 찾을 수 없습니다: $feature_group"
    return 1
  fi
  
  has_online=$(echo "$fg_info" | jq -r '.IngestMode | contains("Online")')
  has_offline=$(echo "$fg_info" | jq -r '.IngestMode | contains("Offline")')
  
  echo "온라인 스토어: $has_online"
  echo "오프라인 스토어: $has_offline"
  
  # 2. 데이터 크기 추정
  echo "📏 2단계: 데이터 크기 추정"
  
  if [ "$has_offline" = "true" ]; then
    if fs analyze "$feature_group" --output-format json > "/tmp/${feature_group}_size.json" 2>/dev/null; then
      size_bytes=$(jq -r '.total_size_bytes // 0' "/tmp/${feature_group}_size.json")
      size_gb=$(echo "scale=2; $size_bytes / (1024^3)" | bc)
      echo "오프라인 스토어 크기: ${size_gb}GB"
      
      if (( $(echo "$size_gb > 10" | bc -l) )); then
        echo "🐘 대용량 Feature Group 감지 - 단계적 삭제 권장"
      fi
    else
      echo "⚠️ 크기 정보를 가져올 수 없습니다"
    fi
    
    rm -f "/tmp/${feature_group}_size.json"
  fi
  
  # 3. 단계적 삭제 계획 수립
  echo "📋 3단계: 삭제 계획"
  stages=()
  
  if [ "$has_online" = "true" ]; then
    stages+=("online_disable:온라인 스토어 비활성화")
    stages+=("online_data:온라인 데이터 삭제")
  fi
  
  if [ "$has_offline" = "true" ]; then
    stages+=("offline_data:오프라인 데이터 삭제")
    stages+=("athena_cleanup:Athena 테이블 정리")
  fi
  
  stages+=("feature_group:Feature Group 리소스 삭제")
  stages+=("metadata:메타데이터 정리")
  
  echo "삭제 단계 (총 ${#stages[@]}단계):"
  for i in "${!stages[@]}"; do
    IFS=':' read -r stage_id stage_desc <<< "${stages[$i]}"
    echo "  $((i+1)). $stage_desc"
  done
  
  echo ""
  echo "예상 소요 시간: $((${#stages[@]} * stage_interval_minutes))분"
  
  # 4. 사용자 확인
  read -p "단계적 삭제를 시작하시겠습니까? (y/n): " confirm
  if [ "$confirm" != "y" ]; then
    echo "❌ 단계적 삭제 취소"
    return 1
  fi
  
  # 5. 단계별 실행
  echo ""
  echo "🚀 단계적 삭제 시작"
  
  for i in "${!stages[@]}"; do
    IFS=':' read -r stage_id stage_desc <<< "${stages[$i]}"
    current_stage=$((i+1))
    
    echo ""
    echo "▶️ 단계 $current_stage/${#stages[@]}: $stage_desc"
    
    case $stage_id in
      "online_disable")
        echo "  ⏸️ 온라인 스토어 비활성화 중..."
        # 실제로는 SageMaker API로 온라인 스토어 비활성화
        sleep 5
        echo "  ✅ 온라인 스토어 비활성화 완료"
        ;;
        
      "online_data")
        echo "  🗑️ 온라인 데이터 삭제 중..."
        # 온라인 데이터는 보통 Feature Group 삭제 시 자동 삭제됨
        sleep 10
        echo "  ✅ 온라인 데이터 삭제 완료"
        ;;
        
      "offline_data")
        echo "  📦 오프라인 데이터 삭제 중..."
        # S3 데이터 삭제는 시간이 오래 걸릴 수 있음
        sleep 20
        echo "  ✅ 오프라인 데이터 삭제 완료"
        ;;
        
      "athena_cleanup")
        echo "  🗄️ Athena 테이블 정리 중..."
        sleep 5
        echo "  ✅ Athena 테이블 정리 완료"
        ;;
        
      "feature_group")
        echo "  🏗️ Feature Group 삭제 중..."
        fs delete "$feature_group" --force --delete-data
        
        if [ $? -eq 0 ]; then
          echo "  ✅ Feature Group 삭제 완료"
        else
          echo "  ❌ Feature Group 삭제 실패"
          return 1
        fi
        ;;
        
      "metadata")
        echo "  🧹 메타데이터 정리 중..."
        sleep 3
        echo "  ✅ 메타데이터 정리 완료"
        ;;
    esac
    
    # 마지막 단계가 아니면 대기
    if [ $current_stage -lt ${#stages[@]} ]; then
      echo "  ⏳ 다음 단계까지 ${stage_interval_minutes}분 대기..."
      
      # 인터럽트 가능한 대기
      for ((j=0; j<stage_interval_minutes; j++)); do
        remaining=$((stage_interval_minutes - j))
        printf "\r  ⏳ 남은 시간: %d분 (Ctrl+C로 중단 가능)" "$remaining"
        sleep 60
      done
      echo ""
    fi
  done
  
  echo ""
  echo "🎉 단계적 삭제 완료!"
  echo "총 소요 시간: $((${#stages[@]} * stage_interval_minutes))분"
}

# 사용 예시
staged_delete "huge-feature-group" 15  # 15분 간격
```

### 6. 복구 불가능 삭제 (Secure Delete)
```bash
#!/bin/bash
secure_delete() {
  local feature_group=$1
  local verification_code=""
  
  echo "🔒 보안 삭제 (Secure Delete): $feature_group"
  echo "⚠️ 이 모드는 모든 흔적을 완전히 제거합니다."
  
  # 1. 보안 확인 코드 생성
  verification_code=$(openssl rand -hex 4 | tr '[:lower:]' '[:upper:]')
  echo ""
  echo "📋 보안 확인 코드: $verification_code"
  echo "이 코드를 정확히 입력해야 삭제가 진행됩니다."
  
  # 2. 다중 확인
  confirmations=0
  required_confirmations=3
  
  echo ""
  echo "🔐 다중 확인 프로세스 ($required_confirmations 단계)"
  
  # 확인 1: Feature Group 이름
  read -p "1/3. 삭제할 Feature Group 이름을 다시 입력하세요: " name_confirm
  if [ "$name_confirm" != "$feature_group" ]; then
    echo "❌ Feature Group 이름이 일치하지 않습니다."
    return 1
  fi
  confirmations=$((confirmations + 1))
  echo "  ✅ 1단계 확인 완료"
  
  # 확인 2: 보안 코드
  read -p "2/3. 보안 확인 코드를 입력하세요: " code_confirm
  if [ "$code_confirm" != "$verification_code" ]; then
    echo "❌ 보안 코드가 일치하지 않습니다."
    return 1
  fi
  confirmations=$((confirmations + 1))
  echo "  ✅ 2단계 확인 완료"
  
  # 확인 3: 위험 인지 확인
  read -p "3/3. 'IRREVERSIBLE DELETE' 를 정확히 입력하세요: " danger_confirm
  if [ "$danger_confirm" != "IRREVERSIBLE DELETE" ]; then
    echo "❌ 위험 인지 확인이 일치하지 않습니다."
    return 1
  fi
  confirmations=$((confirmations + 1))
  echo "  ✅ 3단계 확인 완료"
  
  # 3. 완전 삭제 실행
  echo ""
  echo "🔥 보안 삭제 실행 중..."
  
  # 3-1. 데이터 덮어쓰기 (가능한 경우)
  echo "  🔄 데이터 덮어쓰기 중..."
  
  # S3에서 여러 번 덮어쓰기 (DoD 5220.22-M 방식 시뮬레이션)
  if fs export "$feature_group" "/tmp/secure_delete_dummy.json" --limit 1 2>/dev/null; then
    # 더미 데이터로 덮어쓰기 (3번 패스)
    for pass in 1 2 3; do
      echo "    패스 $pass/3: 더미 데이터 생성 중..."
      
      # 랜덤 데이터 생성 후 업로드
      python3 << EOF > "/tmp/overwrite_data_${pass}.json"
import json
import random
import string

dummy_records = []
for i in range(100):
    dummy_record = {
        "customer_id": "SECURE_DELETE_" + ''.join(random.choices(string.ascii_uppercase, k=10)),
        "event_time": "2000-01-01T00:00:00Z",
        "dummy_field": ''.join(random.choices(string.ascii_letters + string.digits, k=50))
    }
    dummy_records.append(dummy_record)

print(json.dumps(dummy_records, indent=2))
EOF
      
      # 더미 데이터 업로드
      fs bulk-put "$feature_group" "/tmp/overwrite_data_${pass}.json" --batch-size 50 >/dev/null 2>&1
      rm -f "/tmp/overwrite_data_${pass}.json"
      
      sleep 2
    done
    
    echo "  ✅ 데이터 덮어쓰기 완료"
  else
    echo "  ⚠️ 데이터 덮어쓰기 불가 (오프라인 전용 또는 빈 Feature Group)"
  fi
  
  # 3-2. 일반 삭제 실행
  echo "  🗑️ Feature Group 삭제 중..."
  fs delete "$feature_group" --force
  
  if [ $? -ne 0 ]; then
    echo "❌ 보안 삭제 실패"
    return 1
  fi
  
  # 3-3. 메타데이터 추가 정리
  echo "  🧹 메타데이터 완전 정리 중..."
  
  # CloudWatch 로그 그룹 삭제 시도
  aws logs delete-log-group --log-group-name "/sagemaker/feature-groups/$feature_group" 2>/dev/null || true
  
  # 관련 S3 버킷의 버전 정리 시도
  # (실제 환경에서는 버킷 정책에 따라 다름)
  
  sleep 3
  echo "  ✅ 메타데이터 정리 완료"
  
  # 4. 삭제 로그 기록
  echo "  📝 보안 삭제 로그 기록 중..."
  
  secure_delete_log="/tmp/secure_delete_log.txt"
  cat >> "$secure_delete_log" << EOF
========================================
보안 삭제 로그
========================================
Feature Group: $feature_group
삭제 시간: $(date -u +"%Y-%m-%d %H:%M:%S UTC")
확인 코드: $verification_code
삭제 방식: 보안 삭제 (3-Pass Overwrite + Standard Delete)
운영자: $(whoami)
IP 주소: $(curl -s ifconfig.me 2>/dev/null || echo "Unknown")
상태: 완료
========================================

EOF
  
  echo "  ✅ 보안 삭제 로그: $secure_delete_log"
  
  # 5. 완료
  echo ""
  echo "🔒 보안 삭제 완료!"
  echo ""
  echo "📋 삭제 완료 내역:"
  echo "  - Feature Group 완전 제거: ✅"
  echo "  - 데이터 3회 덮어쓰기: ✅"
  echo "  - 메타데이터 정리: ✅"
  echo "  - 보안 로그 기록: ✅"
  echo ""
  echo "⚠️ 중요: 이 삭제는 복구할 수 없습니다."
  
  # 임시 파일 정리
  rm -f "/tmp/secure_delete_dummy.json"
}

# 사용 예시 (매우 신중하게!)
# secure_delete "highly-sensitive-data"
```

## 성능 및 최적화

### 1. 삭제 성능 예측
```bash
#!/bin/bash
estimate_deletion_time() {
  local feature_group=$1
  
  echo "⏱️ 삭제 시간 예측: $feature_group"
  
  # Feature Group 정보 수집
  fg_info=$(fs list -o json | jq --arg fg "$feature_group" \
    '.[] | select(.FeatureGroupName == $fg)')
  
  if [ -z "$fg_info" ]; then
    echo "❌ Feature Group을 찾을 수 없습니다"
    return 1
  fi
  
  has_online=$(echo "$fg_info" | jq -r '.IngestMode | contains("Online")')
  has_offline=$(echo "$fg_info" | jq -r '.IngestMode | contains("Offline")')
  
  total_time=0
  
  echo "📊 예측 분석:"
  
  # Online Store 삭제 시간
  if [ "$has_online" = "true" ]; then
    online_time=60  # 평균 1분
    echo "  Online Store: ~${online_time}초"
    total_time=$((total_time + online_time))
  fi
  
  # Offline Store 삭제 시간 (크기 기반)
  if [ "$has_offline" = "true" ]; then
    echo "  Offline Store 크기 확인 중..."
    
    if fs analyze "$feature_group" --output-format json > "/tmp/size_check.json" 2>/dev/null; then
      size_bytes=$(jq -r '.total_size_bytes // 0' "/tmp/size_check.json")
      size_gb=$(echo "scale=2; $size_bytes / (1024^3)" | bc)
      
      # 크기에 따른 삭제 시간 예측
      if (( $(echo "$size_gb <= 1" | bc -l) )); then
        offline_time=120  # 2분
      elif (( $(echo "$size_gb <= 10" | bc -l) )); then
        offline_time=300  # 5분
      elif (( $(echo "$size_gb <= 100" | bc -l) )); then
        offline_time=900  # 15분
      else
        offline_time=1800  # 30분+
      fi
      
      echo "  Offline Store (${size_gb}GB): ~$((offline_time / 60))분"
      total_time=$((total_time + offline_time))
      
      rm -f "/tmp/size_check.json"
    else
      offline_time=300  # 기본 5분
      echo "  Offline Store (크기 불명): ~$((offline_time / 60))분"
      total_time=$((total_time + offline_time))
    fi
  fi
  
  # 메타데이터 정리
  metadata_time=30
  echo "  메타데이터 정리: ~${metadata_time}초"
  total_time=$((total_time + metadata_time))
  
  echo ""
  echo "📈 총 예상 시간: $((total_time / 60))분 ${total_time}초"
  echo "실제 시간은 네트워크 상황과 AWS 리소스 상태에 따라 달라질 수 있습니다."
}

estimate_deletion_time "large-feature-group"
```

## 오류 처리 및 문제 해결

### 1. 일반적인 삭제 오류
```bash
# 삭제 중 상태 오류
❌ Feature Group이 이미 삭제 중이거나 삭제 실패 상태입니다: Deleting
# 해결: 현재 삭제 프로세스 완료 대기 또는 AWS 콘솔에서 상태 확인

# 권한 오류
❌ AccessDenied: User is not authorized to perform: sagemaker:DeleteFeatureGroup
# 해결: IAM 정책에 sagemaker:DeleteFeatureGroup 권한 추가

# 의존성 오류 
❌ Feature Group cannot be deleted while it has dependencies
# 해결: 의존성 리소스(모델, 파이프라인 등) 먼저 제거

# S3 삭제 권한 오류
❌ S3 데이터 삭제 중 오류: Access Denied
# 해결: S3 버킷에 대한 DeleteObject 권한 확인
```

### 2. 삭제 실패 복구
```bash
#!/bin/bash
recover_failed_deletion() {
  local feature_group=$1
  
  echo "🚨 삭제 실패 복구: $feature_group"
  
  # 현재 상태 확인
  status=$(fs list -o json | jq -r --arg fg "$feature_group" \
    '.[] | select(.FeatureGroupName == $fg) | .FeatureGroupStatus // "NotFound"')
  
  echo "현재 상태: $status"
  
  case $status in
    "DeleteFailed")
      echo "🔄 삭제 실패 상태에서 복구 중..."
      
      # 재시도
      echo "재시도 중..."
      fs delete "$feature_group" --force
      ;;
      
    "Deleting")
      echo "⏳ 삭제 진행 중 - 대기 필요"
      echo "강제 중단 후 재시도? (y/n)"
      read -r response
      
      if [ "$response" = "y" ]; then
        # 강제 재시도 (주의: 권장하지 않음)
        fs delete "$feature_group" --force
      fi
      ;;
      
    "NotFound")
      echo "✅ Feature Group이 이미 삭제되었습니다."
      ;;
      
    *)
      echo "❓ 알 수 없는 상태: $status"
      echo "수동 확인이 필요합니다."
      ;;
  esac
}
```

## 모범 사례

1. **사전 백업**: 중요한 데이터는 반드시 삭제 전 백업
2. **의존성 확인**: 연결된 모델, 파이프라인, 애플리케이션 확인
3. **단계적 접근**: 중요한 Feature Group은 단계적 삭제 고려
4. **권한 검토**: 필요한 최소 권한만 부여
5. **모니터링**: 삭제 프로세스 진행 상황 모니터링
6. **문서화**: 삭제 사유와 과정 문서화

## 관련 명령어
- `fs clear`: 데이터만 삭제 (Feature Group 유지)
- `fs export`: 삭제 전 데이터 백업
- `fs schema`: 삭제 전 스키마 백업
- `fs analyze`: 삭제할 데이터 크기 확인