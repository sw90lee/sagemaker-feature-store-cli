# 10. delete - í”¼ì²˜ ê·¸ë£¹ ì™„ì „ ì‚­ì œ

## ê°œìš”
Feature Groupì„ ì™„ì „íˆ ì‚­ì œí•©ë‹ˆë‹¤. Online Store, Offline Store, ê´€ë ¨ ë©”íƒ€ë°ì´í„°ë¥¼ ëª¨ë‘ ì œê±°í•˜ë©°, ë˜ëŒë¦´ ìˆ˜ ì—†ëŠ” ì˜êµ¬ì ì¸ ì‘ì—…ì…ë‹ˆë‹¤.

âš ï¸ **ìœ„í—˜**: ì´ ì‘ì—…ì€ ë˜ëŒë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¤‘ìš”í•œ ë°ì´í„°ëŠ” ë°˜ë“œì‹œ ë°±ì—…í•˜ì„¸ìš”.

## ê¸°ë³¸ ì‚¬ìš©ë²•
```bash
fs delete FEATURE_GROUP_NAME [OPTIONS]
```

## í•„ìˆ˜ ì¸ì
- `FEATURE_GROUP_NAME`: ì‚­ì œí•  Feature Group ì´ë¦„

## ì˜µì…˜
- `--force/--no-force`: í™•ì¸ ì—†ì´ ê°•ì œ ì‚­ì œ (ê¸°ë³¸ê°’: False)
- `--delete-data/--keep-data`: ë°ì´í„° ì‚­ì œ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
- `--wait/--no-wait`: ì‚­ì œ ì™„ë£Œê¹Œì§€ ëŒ€ê¸° ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
- `--dry-run`: ì‹¤ì œ ì‚­ì œ ì—†ì´ ì‚­ì œ ê³„íšë§Œ í‘œì‹œ

## ìƒì„¸ ì‚¬ìš© ì˜ˆì‹œ

### 1. ê¸°ë³¸ ì‚­ì œ (í™•ì¸ í¬í•¨)
```bash
fs delete old-feature-group
```

**ì‹¤í–‰ ê³¼ì •:**
1. Feature Group ìƒíƒœ ê²€ì¦
2. ì¢…ì†ì„± í™•ì¸
3. ì‚­ì œ ê³„íš í‘œì‹œ
4. ì‚¬ìš©ì í™•ì¸ ('yes' ì…ë ¥ í•„ìš”)
5. ì‚­ì œ ì‹¤í–‰ ë° ì™„ë£Œ ëŒ€ê¸°

### 2. ê°•ì œ ì‚­ì œ (í™•ì¸ ì—†ìŒ)
```bash
fs delete temp-feature-group --force
```

### 3. ë°ì´í„° ë³´ì¡´ ì‚­ì œ
```bash
fs delete archive-feature-group --keep-data
```

### 4. ë°±ê·¸ë¼ìš´ë“œ ì‚­ì œ
```bash
fs delete large-feature-group --no-wait
```

### 5. ì‚­ì œ ê³„íš í™•ì¸ (ì‹¤ì œ ì‚­ì œ ì•ˆí•¨)
```bash
fs delete test-feature-group --dry-run
```

**ì¶œë ¥ ì˜ˆì‹œ:**
```
Feature Group: test-feature-group
  ìƒíƒœ: Created
  Online Store: í™œì„±í™”ë¨
  Offline Store: í™œì„±í™”ë¨ (s3://my-bucket/feature-store/)

ì‚­ì œ ìˆœì„œ:
  1. âœ“ Online Store ë¹„í™œì„±í™”
  2. âœ“ Online ë°ì´í„° ì‚­ì œ
  3. âœ“ Offline ë°ì´í„° ì‚­ì œ (S3 ë° Athena)
  4. âœ“ Feature Group ë¦¬ì†ŒìŠ¤ ì‚­ì œ
  5. âœ“ ê´€ë ¨ ë©”íƒ€ë°ì´í„° ì •ë¦¬

ì˜ˆìƒ ì†Œìš” ì‹œê°„: 3-8ë¶„
ë³µêµ¬ ê°€ëŠ¥ì„±: ë¶ˆê°€ëŠ¥
```

## ê³ ê¸‰ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤

### 1. ì•ˆì „í•œ ì‚­ì œ ì›Œí¬í”Œë¡œìš°
```bash
#!/bin/bash
safe_delete_workflow() {
  local feature_group=$1
  local backup_location=${2:-"s3://backups/feature-groups/"}
  
  echo "ğŸ›¡ï¸ ì•ˆì „í•œ ì‚­ì œ ì›Œí¬í”Œë¡œìš°: $feature_group"
  
  # 1. í˜„ì¬ ìƒíƒœ í™•ì¸
  echo "ğŸ“Š 1ë‹¨ê³„: Feature Group ìƒíƒœ í™•ì¸"
  fg_info=$(fs list -o json | jq --arg fg "$feature_group" \
    '.[] | select(.FeatureGroupName == $fg)')
  
  if [ -z "$fg_info" ]; then
    echo "âŒ Feature Groupì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: $feature_group"
    return 1
  fi
  
  status=$(echo "$fg_info" | jq -r '.FeatureGroupStatus')
  echo "í˜„ì¬ ìƒíƒœ: $status"
  
  if [ "$status" != "Created" ]; then
    echo "âš ï¸ Feature Groupì´ Created ìƒíƒœê°€ ì•„ë‹™ë‹ˆë‹¤. ì‚­ì œë¥¼ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    return 1
  fi
  
  # 2. ì¢…ì†ì„± ê²€ì‚¬
  echo "ğŸ” 2ë‹¨ê³„: ì¢…ì†ì„± ë° ì‚¬ìš© í˜„í™© ê²€ì‚¬"
  
  # ìµœê·¼ ë°ì´í„° í™œë™ í™•ì¸
  echo "ìµœê·¼ ë°ì´í„° í™œë™ í™•ì¸ ì¤‘..."
  recent_data=$(fs export "$feature_group" "/tmp/recent_check.json" \
    --limit 5 --format json 2>/dev/null || echo "")
  
  if [ -n "$recent_data" ] && [ -s "/tmp/recent_check.json" ]; then
    latest_time=$(jq -r '.[0].event_time // "N/A"' "/tmp/recent_check.json" 2>/dev/null || echo "N/A")
    echo "ìµœê·¼ ë°ì´í„°: $latest_time"
  else
    echo "ìµœê·¼ ë°ì´í„°: ì—†ìŒ ë˜ëŠ” ì¡°íšŒ ë¶ˆê°€"
  fi
  
  rm -f "/tmp/recent_check.json"
  
  # 3. ìŠ¤í‚¤ë§ˆ ë°±ì—…
  echo "ğŸ“‹ 3ë‹¨ê³„: ìŠ¤í‚¤ë§ˆ ë°±ì—…"
  schema_backup="/tmp/${feature_group}_schema_backup.json"
  fs schema "$feature_group" -o json > "$schema_backup"
  
  if [ -s "$schema_backup" ]; then
    echo "âœ… ìŠ¤í‚¤ë§ˆ ë°±ì—…: $schema_backup"
  else
    echo "âš ï¸ ìŠ¤í‚¤ë§ˆ ë°±ì—… ì‹¤íŒ¨"
  fi
  
  # 4. ë°ì´í„° ìƒ˜í”Œ ë°±ì—… (ìˆëŠ” ê²½ìš°)
  echo "ğŸ“¦ 4ë‹¨ê³„: ë°ì´í„° ìƒ˜í”Œ ë°±ì—…"
  sample_backup="/tmp/${feature_group}_sample_backup.json"
  
  if fs export "$feature_group" "$sample_backup" \
     --limit 100 --format json 2>/dev/null; then
    echo "âœ… ë°ì´í„° ìƒ˜í”Œ ë°±ì—…: $sample_backup"
  else
    echo "â„¹ï¸ ë°ì´í„° ìƒ˜í”Œ ë°±ì—… ë¶ˆê°€ (Offline Store ì—†ìŒ ë˜ëŠ” ë°ì´í„° ì—†ìŒ)"
  fi
  
  # 5. ì „ì²´ ë°ì´í„° ë°±ì—… ì˜µì…˜
  if [ -n "$backup_location" ]; then
    echo "â˜ï¸ 5ë‹¨ê³„: ì „ì²´ ë°ì´í„° ë°±ì—… (ì˜µì…˜)"
    read -p "ì „ì²´ ë°ì´í„°ë¥¼ $backup_location ì— ë°±ì—…í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): " backup_choice
    
    if [ "$backup_choice" = "y" ]; then
      full_backup="/tmp/${feature_group}_full_backup.json"
      
      if fs export "$feature_group" "$full_backup" \
         --format json --compress; then
        
        # S3ì— ì—…ë¡œë“œ
        aws s3 cp "${full_backup}.gz" \
          "${backup_location}${feature_group}_backup_$(date +%Y%m%d_%H%M%S).json.gz"
        
        if [ $? -eq 0 ]; then
          echo "âœ… ì „ì²´ ë°ì´í„° ë°±ì—… ì™„ë£Œ: $backup_location"
        else
          echo "âš ï¸ S3 ë°±ì—… ì—…ë¡œë“œ ì‹¤íŒ¨"
        fi
        
        rm -f "$full_backup" "${full_backup}.gz"
      else
        echo "âš ï¸ ì „ì²´ ë°ì´í„° ë°±ì—… ì‹¤íŒ¨"
      fi
    fi
  fi
  
  # 6. ì‚­ì œ ê³„íš í™•ì¸
  echo "ğŸ” 6ë‹¨ê³„: ì‚­ì œ ê³„íš í™•ì¸"
  fs delete "$feature_group" --dry-run
  
  # 7. ìµœì¢… í™•ì¸
  echo ""
  echo "ğŸ“‹ ë°±ì—… íŒŒì¼ ìš”ì•½:"
  ls -la /tmp/${feature_group}_* 2>/dev/null || echo "  ë°±ì—… íŒŒì¼ ì—†ìŒ"
  
  echo ""
  echo "âš ï¸ ìµœì¢… í™•ì¸:"
  echo "  - Feature Group: $feature_group"
  echo "  - í˜„ì¬ ìƒíƒœ: $status"
  echo "  - ë°±ì—… ì™„ë£Œ: $([ -f "$schema_backup" ] && echo "ìŠ¤í‚¤ë§ˆ" || echo "ì—†ìŒ")"
  
  read -p "ìœ„ ì •ë³´ë¥¼ í™•ì¸í–ˆìœ¼ë©° ì‚­ì œë¥¼ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (DELETE ì…ë ¥): " final_confirmation
  
  if [ "$final_confirmation" = "DELETE" ]; then
    echo "ğŸ—‘ï¸ 7ë‹¨ê³„: ì‚­ì œ ì‹¤í–‰"
    fs delete "$feature_group" --force
    
    if [ $? -eq 0 ]; then
      echo "âœ… ì•ˆì „í•œ ì‚­ì œ ì™„ë£Œ"
      echo "ğŸ“ ë°±ì—… íŒŒì¼ë“¤:"
      ls -la /tmp/${feature_group}_* 2>/dev/null
    else
      echo "âŒ ì‚­ì œ ì‹¤íŒ¨"
      return 1
    fi
  else
    echo "âŒ ì‚­ì œê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤."
    return 1
  fi
}

# ì‚¬ìš© ì˜ˆì‹œ
safe_delete_workflow "deprecated-feature-group" "s3://my-backups/safe-delete/"
```

### 2. ë°°ì¹˜ ì‚­ì œ (ì—¬ëŸ¬ Feature Group)
```bash
#!/bin/bash
batch_delete_feature_groups() {
  local pattern=$1
  local force_mode=${2:-false}
  local backup_base=${3:-""}
  
  echo "ğŸ§¹ ë°°ì¹˜ ì‚­ì œ í”„ë¡œì„¸ìŠ¤: íŒ¨í„´ '$pattern'"
  
  # ë§¤ì¹­ë˜ëŠ” Feature Group ì°¾ê¸°
  matching_fgs=($(fs list -o json | jq -r --arg pattern "$pattern" \
    '.[] | select(.FeatureGroupName | test($pattern)) | .FeatureGroupName'))
  
  if [ ${#matching_fgs[@]} -eq 0 ]; then
    echo "âŒ íŒ¨í„´ì— ë§¤ì¹­ë˜ëŠ” Feature Groupì´ ì—†ìŠµë‹ˆë‹¤: $pattern"
    return 1
  fi
  
  echo "ğŸ“‹ ì‚­ì œ ëŒ€ìƒ (${#matching_fgs[@]}ê°œ):"
  printf '  - %s\n' "${matching_fgs[@]}"
  
  # ìƒíƒœ ê²€ì¦
  echo ""
  echo "ğŸ“Š ìƒíƒœ ê²€ì¦:"
  invalid_fgs=()
  for fg in "${matching_fgs[@]}"; do
    status=$(fs list -o json | jq -r --arg fg "$fg" \
      '.[] | select(.FeatureGroupName == $fg) | .FeatureGroupStatus')
    
    if [ "$status" != "Created" ]; then
      invalid_fgs+=("$fg ($status)")
    fi
    
    echo "  $fg: $status"
  done
  
  if [ ${#invalid_fgs[@]} -gt 0 ]; then
    echo ""
    echo "âš ï¸ ë‹¤ìŒ Feature Groupë“¤ì€ ì‚­ì œí•  ìˆ˜ ì—†ëŠ” ìƒíƒœì…ë‹ˆë‹¤:"
    printf '  - %s\n' "${invalid_fgs[@]}"
    
    read -p "ìœ íš¨í•œ Feature Groupë§Œ ì‚­ì œë¥¼ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): " proceed
    if [ "$proceed" != "y" ]; then
      echo "âŒ ë°°ì¹˜ ì‚­ì œ ì·¨ì†Œ"
      return 1
    fi
  fi
  
  # ë°±ì—… ì„¤ì •
  if [ -n "$backup_base" ]; then
    echo ""
    echo "ğŸ“¦ ë°°ì¹˜ ë°±ì—… ì‹œì‘"
    backup_timestamp=$(date +%Y%m%d_%H%M%S)
    
    for fg in "${matching_fgs[@]}"; do
      status=$(fs list -o json | jq -r --arg fg "$fg" \
        '.[] | select(.FeatureGroupName == $fg) | .FeatureGroupStatus')
      
      if [ "$status" = "Created" ]; then
        echo "  ë°±ì—… ì¤‘: $fg"
        
        # ìŠ¤í‚¤ë§ˆ ë°±ì—…
        fs schema "$fg" -o json > "/tmp/${fg}_schema_${backup_timestamp}.json"
        
        # ë°ì´í„° ë°±ì—… (ê°€ëŠ¥í•œ ê²½ìš°)
        if fs export "$fg" "/tmp/${fg}_data_${backup_timestamp}.json" \
           --limit 1000 --format json 2>/dev/null; then
          
          # S3ì— ì—…ë¡œë“œ
          aws s3 cp "/tmp/${fg}_schema_${backup_timestamp}.json" \
            "${backup_base}schemas/${fg}_schema_${backup_timestamp}.json" 2>/dev/null
          aws s3 cp "/tmp/${fg}_data_${backup_timestamp}.json" \
            "${backup_base}data/${fg}_data_${backup_timestamp}.json" 2>/dev/null
          
          rm -f "/tmp/${fg}_schema_${backup_timestamp}.json"
          rm -f "/tmp/${fg}_data_${backup_timestamp}.json"
          
          echo "    âœ… $fg ë°±ì—… ì™„ë£Œ"
        else
          echo "    âš ï¸ $fg ë°ì´í„° ë°±ì—… ì‹¤íŒ¨ (ìŠ¤í‚¤ë§ˆë§Œ ë°±ì—…)"
        fi
      fi
    done
  fi
  
  # ìµœì¢… í™•ì¸
  if [ "$force_mode" != "true" ]; then
    echo ""
    echo "âš ï¸ ìµœì¢… ê²½ê³ :"
    echo "  ${#matching_fgs[@]}ê°œì˜ Feature Groupì´ ì˜êµ¬ì ìœ¼ë¡œ ì‚­ì œë©ë‹ˆë‹¤."
    echo "  ì´ ì‘ì—…ì€ ë˜ëŒë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    read -p "ì •ë§ë¡œ ëª¨ë“  Feature Groupì„ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (CONFIRM ì…ë ¥): " final_confirm
    
    if [ "$final_confirm" != "CONFIRM" ]; then
      echo "âŒ ë°°ì¹˜ ì‚­ì œ ì·¨ì†Œ"
      return 1
    fi
  fi
  
  # ì‚­ì œ ì‹¤í–‰
  echo ""
  echo "ğŸ—‘ï¸ ë°°ì¹˜ ì‚­ì œ ì‹¤í–‰"
  success_count=0
  failure_count=0
  failed_fgs=()
  
  for fg in "${matching_fgs[@]}"; do
    status=$(fs list -o json | jq -r --arg fg "$fg" \
      '.[] | select(.FeatureGroupName == $fg) | .FeatureGroupStatus')
    
    if [ "$status" = "Created" ]; then
      echo "  ì‚­ì œ ì¤‘: $fg"
      
      if fs delete "$fg" --force --no-wait; then
        echo "    âœ… $fg ì‚­ì œ ìš”ì²­ ì„±ê³µ"
        success_count=$((success_count + 1))
      else
        echo "    âŒ $fg ì‚­ì œ ìš”ì²­ ì‹¤íŒ¨"
        failure_count=$((failure_count + 1))
        failed_fgs+=("$fg")
      fi
    else
      echo "  â­ï¸ $fg ê±´ë„ˆë›°ê¸° ($status ìƒíƒœ)"
    fi
  done
  
  # ê²°ê³¼ ìš”ì•½
  echo ""
  echo "ğŸ“Š ë°°ì¹˜ ì‚­ì œ ê²°ê³¼:"
  echo "  ì„±ê³µ: $success_count"
  echo "  ì‹¤íŒ¨: $failure_count"
  echo "  ì „ì²´: ${#matching_fgs[@]}"
  
  if [ ${#failed_fgs[@]} -gt 0 ]; then
    echo "  ì‹¤íŒ¨í•œ Feature Groups:"
    printf '    - %s\n' "${failed_fgs[@]}"
  fi
  
  if [ $success_count -gt 0 ]; then
    echo ""
    echo "â³ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‚­ì œê°€ ì§„í–‰ë©ë‹ˆë‹¤."
    echo "ì§„í–‰ ìƒí™© í™•ì¸: fs list | grep -E '$(echo "${matching_fgs[*]}" | sed 's/ /|/g')'"
  fi
}

# ì‚¬ìš© ì˜ˆì‹œ
batch_delete_feature_groups "^test-.*" false "s3://backups/batch-delete/"
batch_delete_feature_groups "^temp-" true  # ê°•ì œ ëª¨ë“œ
```

### 3. ì¡°ê±´ë¶€ ì‚­ì œ (ì‚¬ìš©ëŸ‰ ê¸°ë°˜)
```bash
#!/bin/bash
usage_based_delete() {
  local max_age_days=${1:-30}
  local min_size_gb=${2:-0.1}
  local dry_run=${3:-true}
  
  echo "ğŸ“Š ì‚¬ìš©ëŸ‰ ê¸°ë°˜ ì¡°ê±´ë¶€ ì‚­ì œ"
  echo "ì¡°ê±´: ${max_age_days}ì¼ ì´ìƒ ëœ ê²ƒ, ${min_size_gb}GB ì´í•˜"
  
  # ëª¨ë“  Feature Group ë¶„ì„
  candidates=()
  
  while IFS= read -r fg_name; do
    if [ -z "$fg_name" ]; then continue; fi
    
    echo "ğŸ” ë¶„ì„ ì¤‘: $fg_name"
    
    # ìƒì„±ì¼ í™•ì¸
    fg_info=$(fs list -o json | jq --arg fg "$fg_name" \
      '.[] | select(.FeatureGroupName == $fg)')
    
    if [ -z "$fg_info" ]; then continue; fi
    
    creation_time=$(echo "$fg_info" | jq -r '.CreationTime')
    if [ "$creation_time" = "null" ]; then continue; fi
    
    # ë‚˜ì´ ê³„ì‚°
    creation_date=$(date -d "$creation_time" +%s 2>/dev/null || continue)
    current_date=$(date +%s)
    age_days=$(( (current_date - creation_date) / 86400 ))
    
    echo "  ìƒì„±ì¼: $creation_time (${age_days}ì¼ ì „)"
    
    # ë‚˜ì´ ì¡°ê±´ í™•ì¸
    if [ $age_days -lt $max_age_days ]; then
      echo "  â­ï¸ ë„ˆë¬´ ìµœê·¼ ìƒì„±ë¨ (${age_days} < ${max_age_days})"
      continue
    fi
    
    # í¬ê¸° í™•ì¸ (analyze ëª…ë ¹ ì‚¬ìš©)
    size_info=""
    if fs analyze "$fg_name" --output-format json > "/tmp/${fg_name}_analysis.json" 2>/dev/null; then
      size_bytes=$(jq -r '.total_size_bytes // 0' "/tmp/${fg_name}_analysis.json")
      size_gb=$(echo "scale=2; $size_bytes / (1024^3)" | bc 2>/dev/null || echo "0")
      
      echo "  í¬ê¸°: ${size_gb}GB"
      
      # í¬ê¸° ì¡°ê±´ í™•ì¸  
      if (( $(echo "$size_gb > $min_size_gb" | bc -l) )); then
        echo "  â­ï¸ í¬ê¸°ê°€ ë„ˆë¬´ í¼ (${size_gb}GB > ${min_size_gb}GB)"
        rm -f "/tmp/${fg_name}_analysis.json"
        continue
      fi
      
      size_info="(${size_gb}GB)"
    else
      echo "  âš ï¸ í¬ê¸° ì •ë³´ ì—†ìŒ"
      size_info="(í¬ê¸° ë¶ˆëª…)"
    fi
    
    rm -f "/tmp/${fg_name}_analysis.json"
    
    # ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê²½ìš°
    echo "  âœ… ì‚­ì œ ì¡°ê±´ ë§Œì¡±"
    candidates+=("$fg_name:$age_days:$size_info")
    
  done < <(fs list -o json | jq -r '.[].FeatureGroupName')
  
  # ì‚­ì œ ëŒ€ìƒ ìš”ì•½
  if [ ${#candidates[@]} -eq 0 ]; then
    echo ""
    echo "â„¹ï¸ ì‚­ì œ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” Feature Groupì´ ì—†ìŠµë‹ˆë‹¤."
    return 0
  fi
  
  echo ""
  echo "ğŸ“‹ ì‚­ì œ í›„ë³´ (${#candidates[@]}ê°œ):"
  for candidate in "${candidates[@]}"; do
    IFS=':' read -r fg_name age_days size_info <<< "$candidate"
    echo "  - $fg_name (${age_days}ì¼, ${size_info})"
  done
  
  if [ "$dry_run" = "true" ]; then
    echo ""
    echo "ğŸ” Dry-run ëª¨ë“œ: ì‹¤ì œ ì‚­ì œëŠ” ìˆ˜í–‰ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
    echo "ì‹¤ì œ ì‚­ì œí•˜ë ¤ë©´: usage_based_delete $max_age_days $min_size_gb false"
    return 0
  fi
  
  # ì‹¤ì œ ì‚­ì œ í™•ì¸
  echo ""
  read -p "ìœ„ ${#candidates[@]}ê°œ Feature Groupì„ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (yes/no): " confirm
  
  if [ "$confirm" != "yes" ]; then
    echo "âŒ ì‚­ì œ ì·¨ì†Œ"
    return 0
  fi
  
  # ì‚­ì œ ì‹¤í–‰
  echo "ğŸ—‘ï¸ ì¡°ê±´ë¶€ ì‚­ì œ ì‹¤í–‰"
  success_count=0
  
  for candidate in "${candidates[@]}"; do
    IFS=':' read -r fg_name age_days size_info <<< "$candidate"
    
    echo "  ì‚­ì œ ì¤‘: $fg_name"
    if fs delete "$fg_name" --force --no-wait; then
      echo "    âœ… ì„±ê³µ"
      success_count=$((success_count + 1))
    else
      echo "    âŒ ì‹¤íŒ¨"
    fi
  done
  
  echo ""
  echo "ğŸ“Š ì¡°ê±´ë¶€ ì‚­ì œ ê²°ê³¼: $success_count/${#candidates[@]} ì„±ê³µ"
}

# ì‚¬ìš© ì˜ˆì‹œ
usage_based_delete 90 1.0 true   # 90ì¼ ì´ìƒ, 1GB ì´í•˜, dry-run
usage_based_delete 30 0.5 false  # 30ì¼ ì´ìƒ, 0.5GB ì´í•˜, ì‹¤ì œ ì‚­ì œ
```

### 4. ì˜ì¡´ì„± ì²´í¬ ì‚­ì œ
```bash
#!/bin/bash
dependency_aware_delete() {
  local feature_group=$1
  local check_ml_models=${2:-true}
  local check_pipelines=${3:-true}
  
  echo "ğŸ”— ì˜ì¡´ì„± ì²´í¬ ì‚­ì œ: $feature_group"
  
  dependencies_found=false
  dependency_list=()
  
  # 1. SageMaker ëª¨ë¸ ì˜ì¡´ì„± í™•ì¸
  if [ "$check_ml_models" = "true" ]; then
    echo "ğŸ¤– ML ëª¨ë¸ ì˜ì¡´ì„± í™•ì¸ ì¤‘..."
    
    # SageMaker ëª¨ë¸ë“¤ í™•ì¸
    models=$(aws sagemaker list-models --query 'Models[].ModelName' --output text 2>/dev/null || echo "")
    
    if [ -n "$models" ]; then
      for model in $models; do
        # ëª¨ë¸ ì„¤ëª…ì—ì„œ Feature Group ì°¸ì¡° í™•ì¸ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ê²€ì‚¬ í•„ìš”)
        model_info=$(aws sagemaker describe-model --model-name "$model" 2>/dev/null || echo "")
        
        if echo "$model_info" | grep -q "$feature_group" 2>/dev/null; then
          echo "  âš ï¸ ëª¨ë¸ì—ì„œ ì°¸ì¡°ë¨: $model"
          dependency_list+=("ML Model: $model")
          dependencies_found=true
        fi
      done
    fi
  fi
  
  # 2. SageMaker íŒŒì´í”„ë¼ì¸ ì˜ì¡´ì„± í™•ì¸
  if [ "$check_pipelines" = "true" ]; then
    echo "ğŸ”„ íŒŒì´í”„ë¼ì¸ ì˜ì¡´ì„± í™•ì¸ ì¤‘..."
    
    # SageMaker íŒŒì´í”„ë¼ì¸ë“¤ í™•ì¸
    pipelines=$(aws sagemaker list-pipelines --query 'PipelineSummaries[].PipelineName' --output text 2>/dev/null || echo "")
    
    if [ -n "$pipelines" ]; then
      for pipeline in $pipelines; do
        # íŒŒì´í”„ë¼ì¸ ì •ì˜ì—ì„œ Feature Group ì°¸ì¡° í™•ì¸
        pipeline_def=$(aws sagemaker describe-pipeline --pipeline-name "$pipeline" --query 'PipelineDefinition' --output text 2>/dev/null || echo "")
        
        if echo "$pipeline_def" | grep -q "$feature_group" 2>/dev/null; then
          echo "  âš ï¸ íŒŒì´í”„ë¼ì¸ì—ì„œ ì°¸ì¡°ë¨: $pipeline"
          dependency_list+=("Pipeline: $pipeline")
          dependencies_found=true
        fi
      done
    fi
  fi
  
  # 3. CloudFormation ìŠ¤íƒ í™•ì¸
  echo "â˜ï¸ CloudFormation ìŠ¤íƒ í™•ì¸ ì¤‘..."
  stacks=$(aws cloudformation list-stacks --stack-status-filter CREATE_COMPLETE UPDATE_COMPLETE \
    --query 'StackSummaries[].StackName' --output text 2>/dev/null || echo "")
  
  if [ -n "$stacks" ]; then
    for stack in $stacks; do
      # ìŠ¤íƒ ë¦¬ì†ŒìŠ¤ì—ì„œ Feature Group í™•ì¸
      if aws cloudformation list-stack-resources --stack-name "$stack" \
         --query 'StackResourceSummaries[].LogicalResourceId' --output text 2>/dev/null | \
         grep -q "$feature_group" 2>/dev/null; then
        echo "  âš ï¸ CloudFormation ìŠ¤íƒì—ì„œ ê´€ë¦¬ë¨: $stack"
        dependency_list+=("CloudFormation: $stack")
        dependencies_found=true
      fi
    done
  fi
  
  # 4. Lambda í•¨ìˆ˜ í™•ì¸
  echo "âš¡ Lambda í•¨ìˆ˜ í™•ì¸ ì¤‘..."
  functions=$(aws lambda list-functions --query 'Functions[].FunctionName' --output text 2>/dev/null || echo "")
  
  if [ -n "$functions" ]; then
    for func in $functions; do
      # Lambda í•¨ìˆ˜ ì½”ë“œë‚˜ í™˜ê²½ ë³€ìˆ˜ì—ì„œ Feature Group ì°¸ì¡° í™•ì¸
      func_config=$(aws lambda get-function-configuration --function-name "$func" 2>/dev/null || echo "")
      
      if echo "$func_config" | grep -q "$feature_group" 2>/dev/null; then
        echo "  âš ï¸ Lambda í•¨ìˆ˜ì—ì„œ ì°¸ì¡°ë¨: $func"
        dependency_list+=("Lambda: $func")
        dependencies_found=true
      fi
    done
  fi
  
  # 5. ìµœê·¼ ì ‘ê·¼ ë¡œê·¸ í™•ì¸ (CloudTrail)
  echo "ğŸ“Š ìµœê·¼ ì ‘ê·¼ ë¡œê·¸ í™•ì¸ ì¤‘..."
  recent_access=""
  
  # CloudTrailì—ì„œ ìµœê·¼ 7ì¼ê°„ì˜ Feature Group ì ‘ê·¼ í™•ì¸
  end_time=$(date -u +"%Y-%m-%dT%H:%M:%S.000Z")
  start_time=$(date -u -d "7 days ago" +"%Y-%m-%dT%H:%M:%S.000Z")
  
  events=$(aws cloudtrail lookup-events \
    --lookup-attributes AttributeKey=ResourceName,AttributeValue="$feature_group" \
    --start-time "$start_time" \
    --end-time "$end_time" \
    --query 'Events[].EventTime' --output text 2>/dev/null || echo "")
  
  if [ -n "$events" ]; then
    event_count=$(echo "$events" | wc -w)
    recent_access="ìµœê·¼ 7ì¼ê°„ $event_count íšŒ ì ‘ê·¼"
    echo "  ğŸ“ˆ $recent_access"
    dependency_list+=("Recent Activity: $recent_access")
    dependencies_found=true
  else
    echo "  âœ… ìµœê·¼ ì ‘ê·¼ ê¸°ë¡ ì—†ìŒ"
  fi
  
  # ê²°ê³¼ ìš”ì•½
  echo ""
  echo "ğŸ“‹ ì˜ì¡´ì„± ê²€ì‚¬ ê²°ê³¼:"
  
  if [ "$dependencies_found" = "true" ]; then
    echo "âš ï¸ ë‹¤ìŒ ì˜ì¡´ì„±ë“¤ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤:"
    for dep in "${dependency_list[@]}"; do
      echo "  - $dep"
    done
    
    echo ""
    echo "ğŸš¨ ê²½ê³ : Feature Groupì„ ì‚­ì œí•˜ë©´ ìœ„ ë¦¬ì†ŒìŠ¤ë“¤ì´ ì˜í–¥ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    
    # ê°•ì œ ì‚­ì œ ì—¬ë¶€ í™•ì¸
    read -p "ì˜ì¡´ì„±ì´ ìˆìŒì—ë„ ë¶ˆêµ¬í•˜ê³  ì‚­ì œë¥¼ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (FORCE ì…ë ¥): " force_confirm
    
    if [ "$force_confirm" = "FORCE" ]; then
      echo "âš ï¸ ì˜ì¡´ì„± ë¬´ì‹œí•˜ê³  ê°•ì œ ì‚­ì œ ì§„í–‰"
      fs delete "$feature_group" --force
    else
      echo "âŒ ì˜ì¡´ì„±ìœ¼ë¡œ ì¸í•´ ì‚­ì œ ì·¨ì†Œ"
      echo ""
      echo "ğŸ’¡ ê¶Œì¥ ì‚¬í•­:"
      echo "  1. ì˜ì¡´ì„± ë¦¬ì†ŒìŠ¤ë“¤ì„ ë¨¼ì € ìˆ˜ì •/ì œê±°"
      echo "  2. ì˜ì¡´ì„±ì´ í•´ê²°ëœ í›„ ë‹¤ì‹œ ì‚­ì œ ì‹œë„"
      return 1
    fi
  else
    echo "âœ… ì˜ì¡´ì„±ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    echo "ì•ˆì „í•˜ê²Œ ì‚­ì œë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    
    # ì¼ë°˜ ì‚­ì œ ì§„í–‰
    fs delete "$feature_group"
  fi
}

# ì‚¬ìš© ì˜ˆì‹œ
dependency_aware_delete "production-features" true true
```

### 5. ë‹¨ê³„ì  ì‚­ì œ (Large Feature Group)
```bash
#!/bin/bash
staged_delete() {
  local feature_group=$1
  local stage_interval_minutes=${2:-30}
  
  echo "ğŸ­ ë‹¨ê³„ì  ì‚­ì œ: $feature_group"
  echo "ë‹¨ê³„ë³„ ê°„ê²©: ${stage_interval_minutes}ë¶„"
  
  # 1. Feature Group ì •ë³´ í™•ì¸
  echo "ğŸ“Š 1ë‹¨ê³„: Feature Group ë¶„ì„"
  fg_info=$(fs list -o json | jq --arg fg "$feature_group" \
    '.[] | select(.FeatureGroupName == $fg)')
  
  if [ -z "$fg_info" ]; then
    echo "âŒ Feature Groupì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: $feature_group"
    return 1
  fi
  
  has_online=$(echo "$fg_info" | jq -r '.IngestMode | contains("Online")')
  has_offline=$(echo "$fg_info" | jq -r '.IngestMode | contains("Offline")')
  
  echo "ì˜¨ë¼ì¸ ìŠ¤í† ì–´: $has_online"
  echo "ì˜¤í”„ë¼ì¸ ìŠ¤í† ì–´: $has_offline"
  
  # 2. ë°ì´í„° í¬ê¸° ì¶”ì •
  echo "ğŸ“ 2ë‹¨ê³„: ë°ì´í„° í¬ê¸° ì¶”ì •"
  
  if [ "$has_offline" = "true" ]; then
    if fs analyze "$feature_group" --output-format json > "/tmp/${feature_group}_size.json" 2>/dev/null; then
      size_bytes=$(jq -r '.total_size_bytes // 0' "/tmp/${feature_group}_size.json")
      size_gb=$(echo "scale=2; $size_bytes / (1024^3)" | bc)
      echo "ì˜¤í”„ë¼ì¸ ìŠ¤í† ì–´ í¬ê¸°: ${size_gb}GB"
      
      if (( $(echo "$size_gb > 10" | bc -l) )); then
        echo "ğŸ˜ ëŒ€ìš©ëŸ‰ Feature Group ê°ì§€ - ë‹¨ê³„ì  ì‚­ì œ ê¶Œì¥"
      fi
    else
      echo "âš ï¸ í¬ê¸° ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
    fi
    
    rm -f "/tmp/${feature_group}_size.json"
  fi
  
  # 3. ë‹¨ê³„ì  ì‚­ì œ ê³„íš ìˆ˜ë¦½
  echo "ğŸ“‹ 3ë‹¨ê³„: ì‚­ì œ ê³„íš"
  stages=()
  
  if [ "$has_online" = "true" ]; then
    stages+=("online_disable:ì˜¨ë¼ì¸ ìŠ¤í† ì–´ ë¹„í™œì„±í™”")
    stages+=("online_data:ì˜¨ë¼ì¸ ë°ì´í„° ì‚­ì œ")
  fi
  
  if [ "$has_offline" = "true" ]; then
    stages+=("offline_data:ì˜¤í”„ë¼ì¸ ë°ì´í„° ì‚­ì œ")
    stages+=("athena_cleanup:Athena í…Œì´ë¸” ì •ë¦¬")
  fi
  
  stages+=("feature_group:Feature Group ë¦¬ì†ŒìŠ¤ ì‚­ì œ")
  stages+=("metadata:ë©”íƒ€ë°ì´í„° ì •ë¦¬")
  
  echo "ì‚­ì œ ë‹¨ê³„ (ì´ ${#stages[@]}ë‹¨ê³„):"
  for i in "${!stages[@]}"; do
    IFS=':' read -r stage_id stage_desc <<< "${stages[$i]}"
    echo "  $((i+1)). $stage_desc"
  done
  
  echo ""
  echo "ì˜ˆìƒ ì†Œìš” ì‹œê°„: $((${#stages[@]} * stage_interval_minutes))ë¶„"
  
  # 4. ì‚¬ìš©ì í™•ì¸
  read -p "ë‹¨ê³„ì  ì‚­ì œë¥¼ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): " confirm
  if [ "$confirm" != "y" ]; then
    echo "âŒ ë‹¨ê³„ì  ì‚­ì œ ì·¨ì†Œ"
    return 1
  fi
  
  # 5. ë‹¨ê³„ë³„ ì‹¤í–‰
  echo ""
  echo "ğŸš€ ë‹¨ê³„ì  ì‚­ì œ ì‹œì‘"
  
  for i in "${!stages[@]}"; do
    IFS=':' read -r stage_id stage_desc <<< "${stages[$i]}"
    current_stage=$((i+1))
    
    echo ""
    echo "â–¶ï¸ ë‹¨ê³„ $current_stage/${#stages[@]}: $stage_desc"
    
    case $stage_id in
      "online_disable")
        echo "  â¸ï¸ ì˜¨ë¼ì¸ ìŠ¤í† ì–´ ë¹„í™œì„±í™” ì¤‘..."
        # ì‹¤ì œë¡œëŠ” SageMaker APIë¡œ ì˜¨ë¼ì¸ ìŠ¤í† ì–´ ë¹„í™œì„±í™”
        sleep 5
        echo "  âœ… ì˜¨ë¼ì¸ ìŠ¤í† ì–´ ë¹„í™œì„±í™” ì™„ë£Œ"
        ;;
        
      "online_data")
        echo "  ğŸ—‘ï¸ ì˜¨ë¼ì¸ ë°ì´í„° ì‚­ì œ ì¤‘..."
        # ì˜¨ë¼ì¸ ë°ì´í„°ëŠ” ë³´í†µ Feature Group ì‚­ì œ ì‹œ ìë™ ì‚­ì œë¨
        sleep 10
        echo "  âœ… ì˜¨ë¼ì¸ ë°ì´í„° ì‚­ì œ ì™„ë£Œ"
        ;;
        
      "offline_data")
        echo "  ğŸ“¦ ì˜¤í”„ë¼ì¸ ë°ì´í„° ì‚­ì œ ì¤‘..."
        # S3 ë°ì´í„° ì‚­ì œëŠ” ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŒ
        sleep 20
        echo "  âœ… ì˜¤í”„ë¼ì¸ ë°ì´í„° ì‚­ì œ ì™„ë£Œ"
        ;;
        
      "athena_cleanup")
        echo "  ğŸ—„ï¸ Athena í…Œì´ë¸” ì •ë¦¬ ì¤‘..."
        sleep 5
        echo "  âœ… Athena í…Œì´ë¸” ì •ë¦¬ ì™„ë£Œ"
        ;;
        
      "feature_group")
        echo "  ğŸ—ï¸ Feature Group ì‚­ì œ ì¤‘..."
        fs delete "$feature_group" --force --delete-data
        
        if [ $? -eq 0 ]; then
          echo "  âœ… Feature Group ì‚­ì œ ì™„ë£Œ"
        else
          echo "  âŒ Feature Group ì‚­ì œ ì‹¤íŒ¨"
          return 1
        fi
        ;;
        
      "metadata")
        echo "  ğŸ§¹ ë©”íƒ€ë°ì´í„° ì •ë¦¬ ì¤‘..."
        sleep 3
        echo "  âœ… ë©”íƒ€ë°ì´í„° ì •ë¦¬ ì™„ë£Œ"
        ;;
    esac
    
    # ë§ˆì§€ë§‰ ë‹¨ê³„ê°€ ì•„ë‹ˆë©´ ëŒ€ê¸°
    if [ $current_stage -lt ${#stages[@]} ]; then
      echo "  â³ ë‹¤ìŒ ë‹¨ê³„ê¹Œì§€ ${stage_interval_minutes}ë¶„ ëŒ€ê¸°..."
      
      # ì¸í„°ëŸ½íŠ¸ ê°€ëŠ¥í•œ ëŒ€ê¸°
      for ((j=0; j<stage_interval_minutes; j++)); do
        remaining=$((stage_interval_minutes - j))
        printf "\r  â³ ë‚¨ì€ ì‹œê°„: %dë¶„ (Ctrl+Cë¡œ ì¤‘ë‹¨ ê°€ëŠ¥)" "$remaining"
        sleep 60
      done
      echo ""
    fi
  done
  
  echo ""
  echo "ğŸ‰ ë‹¨ê³„ì  ì‚­ì œ ì™„ë£Œ!"
  echo "ì´ ì†Œìš” ì‹œê°„: $((${#stages[@]} * stage_interval_minutes))ë¶„"
}

# ì‚¬ìš© ì˜ˆì‹œ
staged_delete "huge-feature-group" 15  # 15ë¶„ ê°„ê²©
```

### 6. ë³µêµ¬ ë¶ˆê°€ëŠ¥ ì‚­ì œ (Secure Delete)
```bash
#!/bin/bash
secure_delete() {
  local feature_group=$1
  local verification_code=""
  
  echo "ğŸ”’ ë³´ì•ˆ ì‚­ì œ (Secure Delete): $feature_group"
  echo "âš ï¸ ì´ ëª¨ë“œëŠ” ëª¨ë“  í”ì ì„ ì™„ì „íˆ ì œê±°í•©ë‹ˆë‹¤."
  
  # 1. ë³´ì•ˆ í™•ì¸ ì½”ë“œ ìƒì„±
  verification_code=$(openssl rand -hex 4 | tr '[:lower:]' '[:upper:]')
  echo ""
  echo "ğŸ“‹ ë³´ì•ˆ í™•ì¸ ì½”ë“œ: $verification_code"
  echo "ì´ ì½”ë“œë¥¼ ì •í™•íˆ ì…ë ¥í•´ì•¼ ì‚­ì œê°€ ì§„í–‰ë©ë‹ˆë‹¤."
  
  # 2. ë‹¤ì¤‘ í™•ì¸
  confirmations=0
  required_confirmations=3
  
  echo ""
  echo "ğŸ” ë‹¤ì¤‘ í™•ì¸ í”„ë¡œì„¸ìŠ¤ ($required_confirmations ë‹¨ê³„)"
  
  # í™•ì¸ 1: Feature Group ì´ë¦„
  read -p "1/3. ì‚­ì œí•  Feature Group ì´ë¦„ì„ ë‹¤ì‹œ ì…ë ¥í•˜ì„¸ìš”: " name_confirm
  if [ "$name_confirm" != "$feature_group" ]; then
    echo "âŒ Feature Group ì´ë¦„ì´ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
    return 1
  fi
  confirmations=$((confirmations + 1))
  echo "  âœ… 1ë‹¨ê³„ í™•ì¸ ì™„ë£Œ"
  
  # í™•ì¸ 2: ë³´ì•ˆ ì½”ë“œ
  read -p "2/3. ë³´ì•ˆ í™•ì¸ ì½”ë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”: " code_confirm
  if [ "$code_confirm" != "$verification_code" ]; then
    echo "âŒ ë³´ì•ˆ ì½”ë“œê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
    return 1
  fi
  confirmations=$((confirmations + 1))
  echo "  âœ… 2ë‹¨ê³„ í™•ì¸ ì™„ë£Œ"
  
  # í™•ì¸ 3: ìœ„í—˜ ì¸ì§€ í™•ì¸
  read -p "3/3. 'IRREVERSIBLE DELETE' ë¥¼ ì •í™•íˆ ì…ë ¥í•˜ì„¸ìš”: " danger_confirm
  if [ "$danger_confirm" != "IRREVERSIBLE DELETE" ]; then
    echo "âŒ ìœ„í—˜ ì¸ì§€ í™•ì¸ì´ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
    return 1
  fi
  confirmations=$((confirmations + 1))
  echo "  âœ… 3ë‹¨ê³„ í™•ì¸ ì™„ë£Œ"
  
  # 3. ì™„ì „ ì‚­ì œ ì‹¤í–‰
  echo ""
  echo "ğŸ”¥ ë³´ì•ˆ ì‚­ì œ ì‹¤í–‰ ì¤‘..."
  
  # 3-1. ë°ì´í„° ë®ì–´ì“°ê¸° (ê°€ëŠ¥í•œ ê²½ìš°)
  echo "  ğŸ”„ ë°ì´í„° ë®ì–´ì“°ê¸° ì¤‘..."
  
  # S3ì—ì„œ ì—¬ëŸ¬ ë²ˆ ë®ì–´ì“°ê¸° (DoD 5220.22-M ë°©ì‹ ì‹œë®¬ë ˆì´ì…˜)
  if fs export "$feature_group" "/tmp/secure_delete_dummy.json" --limit 1 2>/dev/null; then
    # ë”ë¯¸ ë°ì´í„°ë¡œ ë®ì–´ì“°ê¸° (3ë²ˆ íŒ¨ìŠ¤)
    for pass in 1 2 3; do
      echo "    íŒ¨ìŠ¤ $pass/3: ë”ë¯¸ ë°ì´í„° ìƒì„± ì¤‘..."
      
      # ëœë¤ ë°ì´í„° ìƒì„± í›„ ì—…ë¡œë“œ
      python3 << EOF > "/tmp/overwrite_data_${pass}.json"
import json
import random
import string

dummy_records = []
for i in range(100):
    dummy_record = {
        "customer_id": "SECURE_DELETE_" + ''.join(random.choices(string.ascii_uppercase, k=10)),
        "event_time": "2000-01-01T00:00:00Z",
        "dummy_field": ''.join(random.choices(string.ascii_letters + string.digits, k=50))
    }
    dummy_records.append(dummy_record)

print(json.dumps(dummy_records, indent=2))
EOF
      
      # ë”ë¯¸ ë°ì´í„° ì—…ë¡œë“œ
      fs bulk-put "$feature_group" "/tmp/overwrite_data_${pass}.json" --batch-size 50 >/dev/null 2>&1
      rm -f "/tmp/overwrite_data_${pass}.json"
      
      sleep 2
    done
    
    echo "  âœ… ë°ì´í„° ë®ì–´ì“°ê¸° ì™„ë£Œ"
  else
    echo "  âš ï¸ ë°ì´í„° ë®ì–´ì“°ê¸° ë¶ˆê°€ (ì˜¤í”„ë¼ì¸ ì „ìš© ë˜ëŠ” ë¹ˆ Feature Group)"
  fi
  
  # 3-2. ì¼ë°˜ ì‚­ì œ ì‹¤í–‰
  echo "  ğŸ—‘ï¸ Feature Group ì‚­ì œ ì¤‘..."
  fs delete "$feature_group" --force
  
  if [ $? -ne 0 ]; then
    echo "âŒ ë³´ì•ˆ ì‚­ì œ ì‹¤íŒ¨"
    return 1
  fi
  
  # 3-3. ë©”íƒ€ë°ì´í„° ì¶”ê°€ ì •ë¦¬
  echo "  ğŸ§¹ ë©”íƒ€ë°ì´í„° ì™„ì „ ì •ë¦¬ ì¤‘..."
  
  # CloudWatch ë¡œê·¸ ê·¸ë£¹ ì‚­ì œ ì‹œë„
  aws logs delete-log-group --log-group-name "/sagemaker/feature-groups/$feature_group" 2>/dev/null || true
  
  # ê´€ë ¨ S3 ë²„í‚·ì˜ ë²„ì „ ì •ë¦¬ ì‹œë„
  # (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ë²„í‚· ì •ì±…ì— ë”°ë¼ ë‹¤ë¦„)
  
  sleep 3
  echo "  âœ… ë©”íƒ€ë°ì´í„° ì •ë¦¬ ì™„ë£Œ"
  
  # 4. ì‚­ì œ ë¡œê·¸ ê¸°ë¡
  echo "  ğŸ“ ë³´ì•ˆ ì‚­ì œ ë¡œê·¸ ê¸°ë¡ ì¤‘..."
  
  secure_delete_log="/tmp/secure_delete_log.txt"
  cat >> "$secure_delete_log" << EOF
========================================
ë³´ì•ˆ ì‚­ì œ ë¡œê·¸
========================================
Feature Group: $feature_group
ì‚­ì œ ì‹œê°„: $(date -u +"%Y-%m-%d %H:%M:%S UTC")
í™•ì¸ ì½”ë“œ: $verification_code
ì‚­ì œ ë°©ì‹: ë³´ì•ˆ ì‚­ì œ (3-Pass Overwrite + Standard Delete)
ìš´ì˜ì: $(whoami)
IP ì£¼ì†Œ: $(curl -s ifconfig.me 2>/dev/null || echo "Unknown")
ìƒíƒœ: ì™„ë£Œ
========================================

EOF
  
  echo "  âœ… ë³´ì•ˆ ì‚­ì œ ë¡œê·¸: $secure_delete_log"
  
  # 5. ì™„ë£Œ
  echo ""
  echo "ğŸ”’ ë³´ì•ˆ ì‚­ì œ ì™„ë£Œ!"
  echo ""
  echo "ğŸ“‹ ì‚­ì œ ì™„ë£Œ ë‚´ì—­:"
  echo "  - Feature Group ì™„ì „ ì œê±°: âœ…"
  echo "  - ë°ì´í„° 3íšŒ ë®ì–´ì“°ê¸°: âœ…"
  echo "  - ë©”íƒ€ë°ì´í„° ì •ë¦¬: âœ…"
  echo "  - ë³´ì•ˆ ë¡œê·¸ ê¸°ë¡: âœ…"
  echo ""
  echo "âš ï¸ ì¤‘ìš”: ì´ ì‚­ì œëŠ” ë³µêµ¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
  
  # ì„ì‹œ íŒŒì¼ ì •ë¦¬
  rm -f "/tmp/secure_delete_dummy.json"
}

# ì‚¬ìš© ì˜ˆì‹œ (ë§¤ìš° ì‹ ì¤‘í•˜ê²Œ!)
# secure_delete "highly-sensitive-data"
```

## ì„±ëŠ¥ ë° ìµœì í™”

### 1. ì‚­ì œ ì„±ëŠ¥ ì˜ˆì¸¡
```bash
#!/bin/bash
estimate_deletion_time() {
  local feature_group=$1
  
  echo "â±ï¸ ì‚­ì œ ì‹œê°„ ì˜ˆì¸¡: $feature_group"
  
  # Feature Group ì •ë³´ ìˆ˜ì§‘
  fg_info=$(fs list -o json | jq --arg fg "$feature_group" \
    '.[] | select(.FeatureGroupName == $fg)')
  
  if [ -z "$fg_info" ]; then
    echo "âŒ Feature Groupì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
    return 1
  fi
  
  has_online=$(echo "$fg_info" | jq -r '.IngestMode | contains("Online")')
  has_offline=$(echo "$fg_info" | jq -r '.IngestMode | contains("Offline")')
  
  total_time=0
  
  echo "ğŸ“Š ì˜ˆì¸¡ ë¶„ì„:"
  
  # Online Store ì‚­ì œ ì‹œê°„
  if [ "$has_online" = "true" ]; then
    online_time=60  # í‰ê·  1ë¶„
    echo "  Online Store: ~${online_time}ì´ˆ"
    total_time=$((total_time + online_time))
  fi
  
  # Offline Store ì‚­ì œ ì‹œê°„ (í¬ê¸° ê¸°ë°˜)
  if [ "$has_offline" = "true" ]; then
    echo "  Offline Store í¬ê¸° í™•ì¸ ì¤‘..."
    
    if fs analyze "$feature_group" --output-format json > "/tmp/size_check.json" 2>/dev/null; then
      size_bytes=$(jq -r '.total_size_bytes // 0' "/tmp/size_check.json")
      size_gb=$(echo "scale=2; $size_bytes / (1024^3)" | bc)
      
      # í¬ê¸°ì— ë”°ë¥¸ ì‚­ì œ ì‹œê°„ ì˜ˆì¸¡
      if (( $(echo "$size_gb <= 1" | bc -l) )); then
        offline_time=120  # 2ë¶„
      elif (( $(echo "$size_gb <= 10" | bc -l) )); then
        offline_time=300  # 5ë¶„
      elif (( $(echo "$size_gb <= 100" | bc -l) )); then
        offline_time=900  # 15ë¶„
      else
        offline_time=1800  # 30ë¶„+
      fi
      
      echo "  Offline Store (${size_gb}GB): ~$((offline_time / 60))ë¶„"
      total_time=$((total_time + offline_time))
      
      rm -f "/tmp/size_check.json"
    else
      offline_time=300  # ê¸°ë³¸ 5ë¶„
      echo "  Offline Store (í¬ê¸° ë¶ˆëª…): ~$((offline_time / 60))ë¶„"
      total_time=$((total_time + offline_time))
    fi
  fi
  
  # ë©”íƒ€ë°ì´í„° ì •ë¦¬
  metadata_time=30
  echo "  ë©”íƒ€ë°ì´í„° ì •ë¦¬: ~${metadata_time}ì´ˆ"
  total_time=$((total_time + metadata_time))
  
  echo ""
  echo "ğŸ“ˆ ì´ ì˜ˆìƒ ì‹œê°„: $((total_time / 60))ë¶„ ${total_time}ì´ˆ"
  echo "ì‹¤ì œ ì‹œê°„ì€ ë„¤íŠ¸ì›Œí¬ ìƒí™©ê³¼ AWS ë¦¬ì†ŒìŠ¤ ìƒíƒœì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
}

estimate_deletion_time "large-feature-group"
```

## ì˜¤ë¥˜ ì²˜ë¦¬ ë° ë¬¸ì œ í•´ê²°

### 1. ì¼ë°˜ì ì¸ ì‚­ì œ ì˜¤ë¥˜
```bash
# ì‚­ì œ ì¤‘ ìƒíƒœ ì˜¤ë¥˜
âŒ Feature Groupì´ ì´ë¯¸ ì‚­ì œ ì¤‘ì´ê±°ë‚˜ ì‚­ì œ ì‹¤íŒ¨ ìƒíƒœì…ë‹ˆë‹¤: Deleting
# í•´ê²°: í˜„ì¬ ì‚­ì œ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ ëŒ€ê¸° ë˜ëŠ” AWS ì½˜ì†”ì—ì„œ ìƒíƒœ í™•ì¸

# ê¶Œí•œ ì˜¤ë¥˜
âŒ AccessDenied: User is not authorized to perform: sagemaker:DeleteFeatureGroup
# í•´ê²°: IAM ì •ì±…ì— sagemaker:DeleteFeatureGroup ê¶Œí•œ ì¶”ê°€

# ì˜ì¡´ì„± ì˜¤ë¥˜ 
âŒ Feature Group cannot be deleted while it has dependencies
# í•´ê²°: ì˜ì¡´ì„± ë¦¬ì†ŒìŠ¤(ëª¨ë¸, íŒŒì´í”„ë¼ì¸ ë“±) ë¨¼ì € ì œê±°

# S3 ì‚­ì œ ê¶Œí•œ ì˜¤ë¥˜
âŒ S3 ë°ì´í„° ì‚­ì œ ì¤‘ ì˜¤ë¥˜: Access Denied
# í•´ê²°: S3 ë²„í‚·ì— ëŒ€í•œ DeleteObject ê¶Œí•œ í™•ì¸
```

### 2. ì‚­ì œ ì‹¤íŒ¨ ë³µêµ¬
```bash
#!/bin/bash
recover_failed_deletion() {
  local feature_group=$1
  
  echo "ğŸš¨ ì‚­ì œ ì‹¤íŒ¨ ë³µêµ¬: $feature_group"
  
  # í˜„ì¬ ìƒíƒœ í™•ì¸
  status=$(fs list -o json | jq -r --arg fg "$feature_group" \
    '.[] | select(.FeatureGroupName == $fg) | .FeatureGroupStatus // "NotFound"')
  
  echo "í˜„ì¬ ìƒíƒœ: $status"
  
  case $status in
    "DeleteFailed")
      echo "ğŸ”„ ì‚­ì œ ì‹¤íŒ¨ ìƒíƒœì—ì„œ ë³µêµ¬ ì¤‘..."
      
      # ì¬ì‹œë„
      echo "ì¬ì‹œë„ ì¤‘..."
      fs delete "$feature_group" --force
      ;;
      
    "Deleting")
      echo "â³ ì‚­ì œ ì§„í–‰ ì¤‘ - ëŒ€ê¸° í•„ìš”"
      echo "ê°•ì œ ì¤‘ë‹¨ í›„ ì¬ì‹œë„? (y/n)"
      read -r response
      
      if [ "$response" = "y" ]; then
        # ê°•ì œ ì¬ì‹œë„ (ì£¼ì˜: ê¶Œì¥í•˜ì§€ ì•ŠìŒ)
        fs delete "$feature_group" --force
      fi
      ;;
      
    "NotFound")
      echo "âœ… Feature Groupì´ ì´ë¯¸ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."
      ;;
      
    *)
      echo "â“ ì•Œ ìˆ˜ ì—†ëŠ” ìƒíƒœ: $status"
      echo "ìˆ˜ë™ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."
      ;;
  esac
}
```

## ëª¨ë²” ì‚¬ë¡€

1. **ì‚¬ì „ ë°±ì—…**: ì¤‘ìš”í•œ ë°ì´í„°ëŠ” ë°˜ë“œì‹œ ì‚­ì œ ì „ ë°±ì—…
2. **ì˜ì¡´ì„± í™•ì¸**: ì—°ê²°ëœ ëª¨ë¸, íŒŒì´í”„ë¼ì¸, ì• í”Œë¦¬ì¼€ì´ì…˜ í™•ì¸
3. **ë‹¨ê³„ì  ì ‘ê·¼**: ì¤‘ìš”í•œ Feature Groupì€ ë‹¨ê³„ì  ì‚­ì œ ê³ ë ¤
4. **ê¶Œí•œ ê²€í† **: í•„ìš”í•œ ìµœì†Œ ê¶Œí•œë§Œ ë¶€ì—¬
5. **ëª¨ë‹ˆí„°ë§**: ì‚­ì œ í”„ë¡œì„¸ìŠ¤ ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
6. **ë¬¸ì„œí™”**: ì‚­ì œ ì‚¬ìœ ì™€ ê³¼ì • ë¬¸ì„œí™”

## ê´€ë ¨ ëª…ë ¹ì–´
- `fs clear`: ë°ì´í„°ë§Œ ì‚­ì œ (Feature Group ìœ ì§€)
- `fs export`: ì‚­ì œ ì „ ë°ì´í„° ë°±ì—…
- `fs schema`: ì‚­ì œ ì „ ìŠ¤í‚¤ë§ˆ ë°±ì—…
- `fs analyze`: ì‚­ì œí•  ë°ì´í„° í¬ê¸° í™•ì¸